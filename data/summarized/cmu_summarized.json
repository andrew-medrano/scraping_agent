[
  {
    "ip_name": "Bio-Inspired Digital Strain Sensor: Advanced Micro-Electro-Mechanical Systems (MEMS) Technology for Rapid and Precise Sensing Solutions",
    "ip_number": "2023-211",
    "published_date": "Jun 20th, 2024",
    "ip_description": "Innovative ohmic-based contact switch that activates at a specific strain threshold, providing precise and reliable detection of periodic strain information. Unlike traditional analog sensors, this technology focuses on the timing of strain threshold crossings rather than the strain's magnitude.\nFeatures beams suspended off a flexible polyethylene terephthalate (PET) substrate configured to add mechanical amplification. This design turns small displacements due to strain into large displacements, effectively closing contact pads and creating an ohmic switch.\nUtilizes a novel fabrication process that includes two-photon polymerization 3D printing, gold layer addition for electrical conductivity, and ultraviolet (UV) laser ablation for electrical isolation. This process ensures precision and efficiency in sensor production. Reduces the speed, cost, and weight of detection compared to current sensors, making it highly efficient and suitable for lightweight applications like flapping wing aerial vehicles.\n\nPrecision and Reliability:The ohmic-based contact switch activates at a specific strain threshold, ensuring precise and reliable detection. This is crucial for applications like structural health monitoring and aerospace engineering.Superior Signal Quality:The digital strain sensor offers a high signal-to-noise ratio, with outputs that can be directly sampled. This eliminates the need for extra amplification hardware and complex signal conditioning, resulting in cleaner, more accurate data.Cost and Efficiency:The fabrication process includes two-photon polymerization 3D printing, gold layer addition, and UV laser ablation for electrical isolation. This method is innovative, reducing production costs and speeding up manufacturing.Mechanical Amplification:Beams suspended off a flexible PET substrate mechanically amplify small displacements into larger movements. This enhances sensitivity, allowing for the detection of minor strain variations in dynamic environments.Lightweight and Compact:Advanced fabrication techniques reduce the need for bulky hardware, making the sensors lightweight and compact. This is ideal for applications where weight and space are limited, such as unmanned aerial vehicles (UAVs) and wearable technology.\n\nUnmanned Aerial Vehicles (UAVs)\nThe sensor's lightweight and flexible design make it ideal for integration into UAV wings to monitor strain and detect disturbances like wind gusts.This can enhance flight stability and control, leading to more reliable and responsive UAVs.\nHealth Monitoring\nFlexible and wearable sensors can be applied to monitor physiological parameters such as muscle strain or joint movement.Can be used in medical devices for patient monitoring, rehabilitation, and fitness tracking.Applications include smart clothing, sports gear, and other wearable tech designed to enhance user experience and performance.\nHumanoid and soft robotic\nThese sensors can provide tactile feedback and monitor structural integrity.Can improve the interaction between robots and their environments, making them more adaptive and sensitive.\nAerospace Engineering\nTo monitor the structural health of aircraft components. This includes detecting strain and stress in wings and other critical parts, contributing to preventive maintenance and safety\nIndustrial Automation\nUse in industrial machinery to monitor strain and stress for predictive maintenance.Reduces downtime and increases operational efficiency through early detection of potential failures.",
    "patents": "18/735,123",
    "page_url": "https://cmu.flintbox.com/technologies/5aed5527-e7f1-41cf-955c-270fd3a6d94b",
    "llm_summary": "**Summary:**  \nThe Bio-Inspired Digital Strain Sensor is an advanced MEMS-based technology featuring an ohmic contact switch that activates at a specific strain threshold, enabling precise and reliable detection of periodic strain. It uses a flexible PET substrate with suspended beams for mechanical amplification, converting small displacements into larger movements to close contact pads. The sensor is fabricated using two-photon polymerization 3D printing, gold layer addition, and UV laser ablation, making it lightweight, cost-effective, and suitable for dynamic environments.\n\n**Applications:**  \n1. Unmanned Aerial Vehicles (UAVs) for monitoring wing strain and enhancing flight stability.  \n2. Health monitoring in wearable devices for tracking muscle strain, joint movement, and physiological parameters.  \n3. Aerospace engineering for structural health monitoring of aircraft components to ensure safety and preventive maintenance.  \n\n**Problem Solved:**  \nThis technology addresses the limitations of traditional analog strain sensors by providing a lightweight, cost-effective, and precise digital solution for detecting strain thresholds, reducing the need for complex signal conditioning and bulky hardware.",
    "llm_teaser": "\"Revolutionize strain sensing with a bio-inspired digital MEMS sensor that combines precision, lightweight design, and cost-efficiency, enabling rapid, reliable detection for applications from UAVs to wearable tech and beyond.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Innovative adaptive audio notifications that can avoid disruption to users' activities",
    "ip_number": "2024-075",
    "published_date": "Mar 14th, 2024",
    "ip_description": "This technology blends the ringtones into whatever background music is playing, making the notifications less abrupt and more harmonious with the ongoing audio environment. This way, users can receive notifications without being jolted out of their current focus, especially whenthey are enjoying music.This technology explores a realm of music-adaptive manipulation parameters to achieve this blending effect. These parameters include beat matching, key matching, and timbre modifications.Enhanced User Experience: By blending notifications harmoniously with background music, MARingBA can create a more pleasant and less intrusive user experience. This is especially beneficial in situations where users are engaged in tasks that require concentration or relaxation.Personalization: The technology's ability to tailor ringtones to different songs allows for a personalized user experience. It can adapt to the user's current music choice, providing a level of personalization that can be appealing to many users.Adaptive Notification Management: MARingBA supports content creators in authoring audio notifications that fit different levels of urgency and noticeability. This adaptability in notification management can be crucial in various scenarios, allowing for a flexible notification delivery system based on the context.Smartphone Markets: The focus of this technology is to blend ringtones with the background music that people often hear using their phones and mobile devices.Retail and Leisure Markets: Background Music (BGM) is extensively utilized in the retail and leisure markets, often integrated within marketing strategies. For instance, digital audio signage is one example where audio notifications could be blended into background music to enhance the shopping experience while informing customers about promotions or important information without causing disruptions\u200b.Industrial Sector: With the growth in wireless audio device market, particularly in manufacturing technologies for small microphones and speakers, there could be potential for deploying MARingBA technology to notify workers of critical alerts or updates seamlessly while they are in a noisy environment or are engaged in other tasks.",
    "patents": "63/603,468",
    "page_url": "https://cmu.flintbox.com/technologies/8cb7834a-41fa-4680-a25d-27a04a3e7ea0",
    "llm_summary": "**Summary:**  \nThis technology, MARingBA, blends ringtones with background music using parameters like beat matching, key matching, and timbre modifications. It creates less disruptive, harmonious notifications, enhancing user experience and personalization while supporting adaptive notification management for varying urgency levels.\n\n**Applications:**  \n1. Smartphone markets for seamless integration of notifications with music.  \n2. Retail and leisure markets for blending audio notifications into background music in stores or digital signage.  \n3. Industrial sector for notifying workers in noisy environments without disruption.  \n\n**Problem Solved:**  \nIt addresses the issue of abrupt and disruptive audio notifications, ensuring users remain focused or relaxed while receiving alerts, particularly in environments with background music or noise.",
    "llm_teaser": "\"Experience seamless notifications that blend harmoniously with your background music, keeping you informed without disrupting your focus or enjoyment\u2014perfect for work, leisure, or noisy environments.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "3D Freeform Printing of Ice as Sacrificial Templates for Rapid Additive Manufacturing",
    "ip_number": "2022-026",
    "published_date": "Mar 13th, 2024",
    "ip_description": "Recent advancements in 3D printing technology have allowed the rapid fabrication of functional parts with complex geometries. Despite this progress, significant challenges remain in printing parts with precise internal features that span multiple length scales, as required for biomedical and medical devices, industrial components, artistic products, and other applications. The traditional 3D printing process involves printing the positive geometry. Although this approach works well for a wide range of shapes, it is inefficient to print mostly solid forms with minute intricate channel-like features such as those commonly encountered in vascularized engineered tissue, 3D microfluidic devices, complex mechanical systems with embedded cooling channels, or pneumatic actuators for soft robotics. The layer-by-layer deposition of positive geometry can result in considerable print times and produce an often-undesirable stepping pattern in the final printed part. In contrast, we propose 3D printing the negative geometry in a frozen state, casting the positive ink, and subsequently eliminating the negative ink to produce the desired form. This process can tremendously reduce processing times and increase production resolution (and thus the manufacturing capability) for structures with internal openings (channels, etc.), primarily when those openings cover a smaller volume than the solid part of the components. Using a high-resolution 3D printing process such as ink-jetting allows printing intricate negative geometries. Traditional 3D inkjet printers typically deposit droplets of specially formulated UV-curable inks cured using an overhead UV lamp. This top-down curing of the ink precludes the printing of overhang structures without support material. Instead, we propose inkjet printing with a liquid (e.g., water, camphene) that will freeze in situ when printed, forming the negative geometry ink. The freezing process can be created by a cold platform or a cooled chamber or both. This technique enables support-free high-resolution fabrication of the negative \"ice\" template. Note that \"ice\" is used as a general term to indicate the frozen state of the printed ink and is not only limited to frozen water. After casting and solidifying the surrounding material (which would form the solid portion of the final component), the sacrificial ice is removed through sublimation, melting, or chemical dissolution, with minimal disruption to the encapsulating positive form. The use of non-toxic and environmentally friendly sacrificial inks, such as water, as the negative ink makes this technology especially attractive for biological and medical applications where the biocompatibility of the ink is an essential consideration.This 3D printing technology revolutionizes the fabrication of parts with complex geometries by focusing on printing the negative geometry in a frozen state, a method that significantly reduces processing times and increases the precision of internal features. This innovative approach allows for the support-free, high-resolution creation of intricate designs, particularly benefiting sectors requiring detailed internal channels, such as biomedical devices, microfluidic systems, and industrial components. Additionally, the use of environmentally friendly and biocompatible materials like water for the sacrificial ink enhances its applicability in sensitive applications, making it a groundbreaking solution that addresses the limitations of traditional 3D printing methods.Biomedical and Healthcare:\nVascularized Tissue Engineering: Creation of tissues with intricate vascular networks for improved organ and tissue regeneration.\nCustom Medical Implants: Fabrication of personalized implants tailored to individual patient anatomy.\nDrug Delivery Systems: Development of devices with complex internal structures for targeted drug release.\nMicrofluidics:\nLab-on-a-Chip Devices: Compact, efficient devices for diagnostics, drug discovery, and biochemical assays.\nOrgan-on-a-Chip Systems: Platforms that mimic physiological responses of organ systems for research and testing.\nAerospace and Automotive:\nLightweight Components: Production of parts with complex internal geometries for weight reduction without compromising strength.\nCooling Systems: Advanced cooling channels in engines and electronics for improved thermal management.\nConsumer Electronics:\nCompact, High-Efficiency Heat Exchangers: Enhanced cooling solutions for small, densely packed electronic devices.\nCustom Enclosures: Tailored enclosures with intricate designs for aesthetic and functional purposes.\nRobotics and Automation:\nSoft Robotics: Fabrication of soft pneumatic actuators with complex internal channels for more nuanced movements.\nCustomized Grippers and Connectors: Parts with specific internal geometries for optimized performance in automated systems.\nArt and Design:\nComplex Artistic Creations: Sculptures and artifacts with detailed internal and external geometries that are difficult or impossible to create with traditional methods.\nEducation and Research:\nEducational Models: Detailed anatomical models for medical and scientific education.\nPrototype Development: Rapid prototyping of research devices with complex internal features.",
    "patents": "PCT/US2022/041539",
    "page_url": "https://cmu.flintbox.com/technologies/7b8f1147-672c-4dd1-a6a0-8af70af8f85a",
    "llm_summary": "**Summary:** This technology introduces a novel 3D printing method that uses frozen sacrificial templates (e.g., ice) to create complex internal geometries. By printing the negative geometry in a frozen state, it enables support-free, high-resolution fabrication of intricate designs, significantly reducing processing times and improving precision. The use of environmentally friendly and biocompatible materials like water makes it ideal for sensitive applications.\n\n**Applications:** Key applications include biomedical devices (e.g., vascularized tissue engineering, custom implants), microfluidics (e.g., lab-on-a-chip devices), and industrial components (e.g., lightweight aerospace parts, advanced cooling systems).\n\n**Problem Solved:** Traditional 3D printing struggles with efficiently producing parts that have intricate internal channels or features, often resulting in long print times and lower resolution. This technology addresses these limitations by focusing on printing negative geometries in a frozen state, enabling faster and more precise fabrication of complex structures.",
    "llm_teaser": "\"Revolutionize 3D printing with ice-based sacrificial templates, enabling rapid, support-free fabrication of intricate internal channels for biomedical, industrial, and artistic applications\u2014all while using eco-friendly, biocompatible materials.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "DiscoBand: Multiview Depth-Sensing Smartwatch Strap",
    "ip_number": "22-067",
    "published_date": "Jun 9th, 2023",
    "ip_description": "This invention enables imaging and estimating the pose of the hand, body, and nearby environment through multi-view depth sensing via a sensor band worn on the wrist. The low-resolution depth data is more privacy preserving than conventional camera-based wrist systems. The device has the ability to estimate user upper body pose, detect held objects, and scan the environment for obstacles and contextual clues.Real-time tracking of a user\u2019s hands, arms and environment is valuable in a wide variety of human-computer interaction applications, from context awareness to virtual reality. Rather than rely on fixed and external tracking infrastructure, the most flexible and consumer-friendly approaches are mobile, self-contained, and compatible with popular device form factors (e.g., smartwatches).This invention enables imaging and estimating the pose of the hand, body, and nearby environment through multi-view depth sensing via a sensor band worn on the wrist. The sensing band is thin and self contained, in a form factor similar to a smartwatch strap. Arranging the orientation and position of depth sensors on the strap, allows for the ability to image different features of interest, such as the hand, torso, or environment. The device solves problems with a bulky form factor and imaging occlusion that are present in similar devices. Beyond the hardware and physical construction, firmware has also been developed to boost the bandwidth of sensor data that is able to be collected from the strap and software to process sensor data into actionable output for specific applications. Example applications for this device include static hand gesture recognition, continuous hand pose estimation, arm pose estimation, object recognition, and environmental mapping.This technology offers a unique combination of features and properties. The band is thin, and could be integrated into future smartwatches. In addition, the multi-view approach is more robust to occlusion than single-view methods. The low-resolution depth data is more privacy preserving than conventional camera-based wrist systems. Lastly, the band's unique design and data opens entirely new capabilities not previously demonstrated with wrist-worn setups, including the ability to estimate user upper body pose, detect held objects, and scan the environment for obstacles and contextual clues.Virtual Reality (VR) and Augmented Reality (AR): Hand tracking is crucial for providing immersive experiences in VR and AR applications. With the ability to accurately track hand movements and gestures, users can interact with virtual objects and interfaces naturally. The market for hand position sensing in VR and AR is expected to grow as these technologies become more mainstream.*Gaming: Hand position sensing can enhance the gaming experience by allowing players to control and interact with games using natural hand movements. This can range from simple gestures to more complex actions. The gaming industry is constantly looking for new ways to improve user engagement and interactivity, making hand position sensing a potentially valuable market.*Robotics and Industrial Automation: In robotics and industrial automation, hand position sensing can be used for human-robot interaction, collaborative robots, and precise control of robotic arms. These applications are relevant in manufacturing, healthcare, logistics, and other industries where human-robot collaboration is increasing. The market for hand position sensing in robotics and automation is expected to grow as these technologies continue to advance.*Rehabilitation and Healthcare: Hand position sensing can play a vital role in rehabilitation and healthcare applications. It can be used for monitoring and assessing hand movements in patients with neurological disorders, tracking progress during therapy, and designing personalized rehabilitation programs. The market potential for hand position sensing in healthcare and rehabilitation is driven by the increasing demand for advanced technology solutions in these areas.*Human-Computer Interaction (HCI): Hand position sensing can enable new modes of interaction with computers and devices. It can be used for touchless interfaces, gesture-based controls, and natural user interfaces. As HCI continues to evolve and adapt to user needs, hand position sensing technologies can find applications in various domains, including smart homes, automotive interfaces, and public displays.*",
    "patents": "63/419,804",
    "page_url": "https://cmu.flintbox.com/technologies/5103888f-bce9-421e-aea2-9292a46002d3",
    "llm_summary": "**Summary:**  \nDiscoBand is a thin, wrist-worn sensor strap that uses multi-view depth sensing to image and estimate the pose of the hand, body, and nearby environment. It offers privacy-preserving, low-resolution depth data and solves issues like bulkiness and occlusion found in similar devices. The technology enables real-time tracking of hands, arms, and surroundings, with applications in gesture recognition, environmental mapping, and upper body pose estimation.\n\n**Applications:**  \n1. Virtual Reality (VR) and Augmented Reality (AR) for immersive hand tracking and interaction.  \n2. Robotics and Industrial Automation for human-robot collaboration and precise control.  \n3. Rehabilitation and Healthcare for monitoring hand movements and therapy progress.  \n\n**Problem Solved:**  \nThis technology addresses the limitations of bulky form factors and imaging occlusion in wrist-worn devices, while providing privacy-preserving depth sensing for real-time hand, body, and environmental tracking.",
    "llm_teaser": "\"DiscoBand: A sleek, privacy-preserving smartwatch strap that revolutionizes human-computer interaction by enabling real-time, multi-view depth sensing for hand, body, and environmental tracking\u2014unlocking immersive VR/AR, intuitive gaming, and seamless robotics control in a compact, wearable form.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "21-365 3D Passive Dynamics-Inspired Walking Robot",
    "ip_number": "63/415,316",
    "published_date": "Jun 9th, 2023",
    "ip_description": "The robot is easy to control -- there are a wide range of amplitudes, frequencies, and profiles of control that lead to stable walking, and that control can be open-loop (does not need sensor feedback).This robot is simpler than previous state of the art bipedal robots inspired by passive walking.The robot technology can be made at a range of size scales.Today we are seeing more of an emergence of legged robots, and especially bipedal robot technology. These robots have the possibility to traverse difficult terrain that wheeled or tracked robots could not. However, current bipedal robots are large and typically designed to need a large amount of sensing, actuation, and control. Some of the more elegant and modern bipedal robots that use torque control still need to be powered and command actuators to stand upright.This robot technology is a quasi-passive, three-dimensional, bipedal walker device. The robot weighs a magnitude less than other previous bipedal robots inspired by passive walkers. The robot had a much smaller leg length, in turn, making the robot slower than other robots. However, when scaled for leg lengths per second traveled, this robot is near the same speed as others. With only 2 actuated degrees of freedom and no feedback from sensors to the environment, this robot is simpler than previous state of the art bipedal robots inspired by passive walking.Industrial Robotics: Bipedal robots are increasingly being deployed in industrial settings for tasks that require human-like dexterity and mobility. These robots can navigate complex environments, interact with objects, and perform tasks such as assembly, inspection, and logistics. They offer advantages over traditional robotic arms or wheeled robots by providing greater mobility and versatility.*Healthcare and Rehabilitation: Bipedal walkers have significant potential in the healthcare industry, particularly for assisting individuals with mobility impairments and rehabilitation. These robots can provide physical support, help with balance, and assist patients in regaining mobility and strength. The market for healthcare robotics, including bipedal walkers, is projected to grow as the aging population increases and the demand for assistive devices rises.*Research and Development: Bipedal walkers play a crucial role in robotics research and development. They are utilized in academic institutions and laboratories for studying human locomotion, balance control, and developing advanced control algorithms. The research market drives innovation and pushes the boundaries of bipedal walking technology, contributing to advancements in the field.*Entertainment and Social Robots: Humanoid robots are gaining popularity in the entertainment industry, including theme parks, exhibitions, and interactive displays. These robots can entertain and engage with audiences through various interactions, such as dancing, performing, and providing information. Additionally, there is a growing market for social robots that can act as companions for individuals seeking social interaction or emotional support.*Defense and Security: Bipedal walkers have potential applications in the military and defense sector. They can be used for reconnaissance, surveillance, and handling hazardous materials in challenging terrains. These robots offer advantages in terms of adaptability and mobility, allowing them to navigate rough terrain or environments where traditional vehicles may struggle.*Education and STEM: Bipedal walkers are finding their way into educational institutions as tools for teaching science, technology, engineering, and mathematics (STEM) subjects. They provide hands-on learning opportunities, enabling students to explore robotics, programming, and mechanics in a practical and engaging manner.*",
    "patents": "63/415,316",
    "page_url": "https://cmu.flintbox.com/technologies/ca6e4535-c5dc-41dc-b0cd-ffc0dfcc3d5c",
    "llm_summary": "**Summary:**  \nThe 21-365 3D Passive Dynamics-Inspired Walking Robot is a lightweight, quasi-passive bipedal robot with only 2 actuated degrees of freedom and no need for sensor feedback. It is simpler and easier to control than previous bipedal robots, offering stable walking across a range of control parameters. The robot can be scaled to various sizes and is designed for efficient, open-loop operation.  \n\n**Applications:**  \n1. Industrial Robotics: Tasks requiring human-like mobility, such as assembly, inspection, and logistics.  \n2. Healthcare and Rehabilitation: Assisting individuals with mobility impairments and aiding in rehabilitation.  \n3. Research and Development: Studying human locomotion and advancing control algorithms in robotics.  \n\n**Problem Solved:**  \nThis technology addresses the complexity and high cost of current bipedal robots by offering a simpler, lightweight, and scalable solution that does not rely on extensive sensing or feedback systems.",
    "llm_teaser": "\"Revolutionizing bipedal robotics, the 21-365 3D Passive Dynamics-Inspired Walking Robot achieves stable, open-loop walking with just 2 actuated degrees of freedom\u2014no sensors needed\u2014offering unmatched simplicity, scalability, and efficiency for diverse applications from healthcare to industrial automation.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "SOT-MRAM: Unconventional Spin-Orbit Torque Generated in a Low-Crystal Symmetry Quantum Material",
    "ip_number": "21-107",
    "published_date": "Jun 9th, 2023",
    "ip_description": "This technology overcomes previous limitations existing in spin-orbit torque (SOT) devices by performing deterministic switching of a magnetization state of a perpendicular magnetic anisotropy (\u201cPMA\u201d) magnet using out-of-plane antidamping SOT in layered materials having low symmetry crystal structure without the need for an external biasing magnetic field.The out-of-plane antidamping torque in WTe2 is essential to explain the observed magnetization switching. Having a material that can switch magnetism without the need of an external magnetic field can lead to energy-efficient data storage and logic devices.Spin-orbit torque MRAM (SOT-MRAM) is a type of non-volatile memory technology that utilizes the spin-orbit interaction of electrons to read, write, and store data. Spin\u2013orbit torque (SOT)-driven deterministic control of the magnetic state of a ferromagnet with perpendicular magnetic anisotropy is key to next-generation spintronic applications including non-volatile, ultrafast and energy-efficient data-storage devices.However, field-free deterministic switching of perpendicular magnetization remains a challenge because it requires an out-of-plane antidamping torque, which is not allowed in conventional spin-source materials such as heavy metals and topological insulators due to the system\u2019s symmetry. The exploitation of low-crystal symmetries in emergent quantum materials offers a unique approach to achieve SOTs with unconventional forms.This technology is a realization of field-free deterministic magnetic switching of a perpendicularly polarized van der Waals magnet employing an out-of-plane antidamping Spin-orbit torque (SOT) generated in layered WTe2 (tungsten ditelluride), a quantum material with a low-symmetry crystal structure. The numerical simulations suggest that the out-of-plane antidamping torque in WTe2 is essential to explain the observed magnetization switching. The way atoms are configured in WTe2 allows for an out-of-plane oriented spin current that in turn can be used to control the magnetization state of a magnet. Having a material that can switch magnetism without the need of an external magnetic field can lead to energy-efficient data storage and logic devices.Computing and Data Storage: The computing industry can benefit from SOT-MRAM in applications such as servers, data centers, and high-performance computing. SOT-MRAM's fast read and write speeds, low power consumption, and non-volatile nature make it an attractive option for main memory, cache memory, and storage class memory. It can enhance the overall performance and energy efficiency of computing systems.Consumer Electronics: SOT-MRAM can have applications in various consumer electronic devices, including smartphones, tablets, laptops, gaming consoles, and wearable devices. It can provide fast, reliable, and non-volatile memory for storing data, improving user experience, and enabling faster boot times and data access.Internet of Things (IoT): The IoT industry can benefit from SOT-MRAM due to its low power consumption, non-volatility, and high endurance. SOT-MRAM can be used in IoT devices for storing firmware, configuration data, event logs, and sensor data. It ensures reliable and energy-efficient data storage in IoT applications such as smart homes, industrial automation, healthcare devices, and smart cities.Automotive: SOT-MRAM's resistance to high temperatures, high endurance, and non-volatile nature make it suitable for the automotive industry. It can be used in infotainment systems, instrument clusters, advanced driver-assistance systems (ADAS), and other automotive electronics, providing reliable and fast memory for critical data storage.Aerospace and Defense: The aerospace and defense industries require memory solutions that can withstand harsh environmental conditions, radiation, and high temperatures. SOT-MRAM's resilience to such conditions makes it a potential candidate for aerospace and defense applications. It can be used in avionics systems, satellite communication, radar systems, and other mission-critical applications.Industrial Automation: SOT-MRAM can find applications in industrial automation systems, providing high-speed, non-volatile memory for data storage, control algorithms, and configuration data. Its robustness, resistance to radiation, and high-temperature tolerance make it suitable for harsh industrial environments.Medical Devices: SOT-MRAM's non-volatile memory capabilities and low power consumption are advantageous for medical devices such as implantable devices, patient monitoring systems, and medical imaging equipment. It can store critical patient data, ensure reliable operation, and contribute to extended battery life.some aspects of this description were generated using ChatGTP and modified to fit the objectives of the description.",
    "patents": "PCT/US2021/060345\nWO2022115379A1",
    "page_url": "https://cmu.flintbox.com/technologies/4eb75d20-01fb-4e1a-9ec5-cd9dc0217fc0",
    "llm_summary": "**Summary:** This technology enables deterministic switching of perpendicular magnetic anisotropy (PMA) magnets using out-of-plane antidamping spin-orbit torque (SOT) in low-symmetry crystal materials like WTe2, eliminating the need for an external magnetic field. It offers energy-efficient, ultrafast, and non-volatile data storage and logic devices, leveraging the unique spin current properties of WTe2.\n\n**Applications:** Key applications include computing and data storage (servers, data centers, high-performance computing), consumer electronics (smartphones, tablets, wearables), and IoT (smart homes, industrial automation, healthcare devices).\n\n**Problem Solved:** It addresses the challenge of field-free deterministic switching of perpendicular magnetization, which is not achievable with conventional spin-source materials due to symmetry constraints, enabling more efficient and compact spintronic devices.",
    "llm_teaser": "\"Revolutionize data storage and computing with SOT-MRAM: a breakthrough technology enabling energy-efficient, field-free magnetic switching using low-symmetry quantum materials like WTe2, unlocking ultrafast, non-volatile memory for next-gen devices.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Privacy Label Wiz - A Tool to Help iOS Application Developers Create Accurate Privacy Labels",
    "ip_number": "2023-144",
    "published_date": "Mar 22nd, 2023",
    "ip_description": "Privacy Label Wiz (PLW) is a desktop application intended for use by iOS application developers to help them create accurate privacy labels. Privacy Label Wiz is integrated with XCode IDE. PLW scans iOS application source code locally on a developers device to identify the use of iOS permissions, present results to developers, and provide them with an interactive UI designed to prompt developers to carefully consider the functionality of their iOS application. With the analysis of source code and interactive functionality, Privacy Label Wiz helps developers to properly disclose the data practices of their application when creating a privacy label for their application on the Apple App Store.In December 2020, Apple began requiring developers to disclose their data collection and use practices to generate a \u201cprivacy label\u201d for their application. The use of mobile application Software Development Kits (SDKs) and third-party libraries, coupled with a typical lack of expertise in privacy, makes it challenging for developers to accurately report their data collection and use practices.In this work we discuss the design and evaluation of a tool to help iOS developers generate privacy labels. The tool combines static code analysis to identify likely data collection and use practices with interactive functionality designed to prompt developers to elucidate analysis results and carefully reflect on their applications\u2019 data practices. We conducted semi-structured interviews with iOS developers as they used an initial version of the tool. We discuss how these results motivated us to develop an enhanced software tool, Privacy Label Wiz, that more closely resembles interactions developers reported to be most useful in our semi-structured interviews. We present findings from our interviews and the enhanced tool motivated by our study. We also outline future directions for software tools to better assist developers communicating their mobile app\u2019s data practices to different audiences.iOS application developers",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/a859b9fe-7ad7-4031-8165-65fe99da3ff1",
    "llm_summary": "**Summary:**  \nPrivacy Label Wiz (PLW) is a desktop application integrated with XCode IDE that helps iOS developers create accurate privacy labels by scanning source code to identify iOS permissions and providing an interactive UI to reflect on data practices. It combines static code analysis with developer prompts to ensure proper disclosure of data collection and use practices for Apple App Store privacy labels.\n\n**Applications:**  \n1. Assisting iOS developers in generating accurate privacy labels for their applications.  \n2. Enhancing transparency in data collection and use practices for mobile apps.  \n3. Supporting compliance with Apple\u2019s privacy label requirements for App Store submissions.  \n\n**Problem Solved:**  \nPrivacy Label Wiz addresses the challenge iOS developers face in accurately reporting their app\u2019s data collection and use practices, especially when using SDKs and third-party libraries, by providing a tool that simplifies and ensures accurate privacy label creation.",
    "llm_teaser": "\"Privacy Label Wiz empowers iOS developers to effortlessly create accurate App Store privacy labels by combining static code analysis with an intuitive, interactive UI, ensuring compliance and transparency in data practices.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "A Safety Architecture for Autonomous Vehicles",
    "ip_number": "2016-130",
    "published_date": "Feb 15th, 2023",
    "ip_description": "This is a general-purpose architecture that allows autonomy components with arbitrarily bad failure modes to be integrated into a high-dependability framework. In this architecture, autonomy components are allowed to fail while \u201csafety gate\u201d components uphold safety requirements. The safety architecture includes a reusable design pattern which can serve as a basis for the safe control of any robotic or other autonomous or semi-autonomous system, as well as any system that must be built as a composition of high dependability and low dependability components.A Safety Architecture for Autonomous Vehiclesdescribes an architecture for autonomous vehicles that incorporates arbitrary autonomy algorithms into a system that upholds strict safety requirements. In this architecture, autonomy components are allowed to fail arbitrarily, even maliciously, while higher-integrity (e.g., higher Safety Integrity Level) \u201csafety gate\u201d components, which might be built without the need for autonomy techniques, uphold safety requirements. A set of architectural stages is created based on a reusable architectural pattern for mapping, planning, and executing safe trajectories. Each stage includes a primary \u201cdoer/checker\u201d pair, and an optional secondary \u201cdoer/checker\u201d pair to provide a degraded mode of operation in case the primary pair fails. InA Safety Architecture for Autonomous Vehicles,\u201cdoing\u201d means performing autonomous control, while \u201cchecking\u201d means confirming that the control signals are safe to execute. If successfully applied, this doer/checker principle may be a suitable option for adoption by safety standards for building dependable systems.A Safety Architecture for Autonomous Vehiclesmay be implemented to realize one or more of the following potential advantages:The gap between complex autonomy algorithms and dependable software systems may be bridged by allowing autonomy components to be integrated into a high-dependability framework. Such framework may assure safe system operation even when individual components, such as autonomy components, fail in an arbitrarily bad manner (e.g., both accidental faults and maliciously unsafe behavior by an individual component).Fail-operational system-level behavior may be provided even when individual components fail or must be shut down due to unsafe component-level behaviors.Heterogeneous functional modules may be provided to reduce the chance of common mode failures, and degraded mode behavior may be provided to, for example, perform a safing mission when primary functionality fails.A Safety Architecture for Autonomous Vehiclesis general-purpose for application in any autonomous system including, without limitation, fully autonomous ground vehicles, semi-autonomous ground vehicles, air vehicles, and other robotic systems with complete or partial autonomy.The architectural pattern is additionally applicable to non-autonomy applications having a mixture of less-trustworthy components (e.g., off-the-shelf software components) and more trustworthy components (e.g., safety critical components).",
    "patents": "US10962972B2; EP17763681.8A; CN201780015446.3A; JP2018535143A; ES17763681T; PCT/US2017/012321",
    "page_url": "https://cmu.flintbox.com/technologies/90c11a12-1f15-4e07-b7ac-b59ee82443df",
    "llm_summary": "**Summary:**  \nThis technology presents a safety architecture for autonomous vehicles that integrates autonomy components with potentially high failure rates into a high-dependability framework. It uses \"safety gate\" components to ensure safety requirements are met, even if autonomy components fail arbitrarily or maliciously. The architecture employs a reusable \"doer/checker\" design pattern, enabling fail-operational behavior and degraded modes for safe operation during component failures.\n\n**Applications:**  \n1. Fully or semi-autonomous ground vehicles (e.g., self-driving cars).  \n2. Air vehicles and other robotic systems with partial or complete autonomy.  \n3. Systems requiring integration of less-trustworthy components (e.g., off-the-shelf software) with safety-critical components.  \n\n**Problem Solved:**  \nThe technology addresses the challenge of integrating complex, potentially unreliable autonomy algorithms into systems that must meet strict safety requirements, ensuring safe operation even when individual components fail arbitrarily or maliciously.",
    "llm_teaser": "\"Revolutionize autonomous systems with a fail-safe architecture that integrates unreliable autonomy components into a high-dependability framework, ensuring safety even in the face of arbitrary or malicious failures.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Ubicoustics: Plug-and-Play Acoustic Activity Recognition",
    "ip_number": "2018-251",
    "published_date": "Aug 23rd, 2022",
    "ip_description": "Ubicoustics is a sound sensing and classification technology which utilizes an extensively trained sound processing algorithm to detect the surrounding activity through real-time sound captured by microphones in everyday smart devices (smart watches, speakers, laptops, smartphones).The technology has been trained using professional sound data from the entertainment industry with highly specific sounds which are then classified into a particular group to accurately label the activity and its surrounding environment leveraging the unique properties of sound and sound effects.The technology is designed to be plug and play and usable to the end-user with just a software update for the smart devices which eliminates the need to store end-user or in-situ data and the need to calibrate or train the model again.This novel technology can transform smart devices into more environment and activity-conscious tool in turn increasing the potential of these devices to be more than just a single-purpose device. Since most of the smart devices (Amazon Echo dot, Apple Homepod etc.) already have a microphone, this technology would require no external hardware to function. Additionally, it is developed in a way which would restrict the collection of data at the end-user to effectively ensure user privacy and adaptability\n\n**Productivity and Maintenance:**\u2022 Limiting worker interruptions in the workplace (reduce interruption costs)\u2022 Equipment utilization (predicting machine lifecycles, maintenance checks and safety) **Guided and Assistive Services through Smart Devices:**\u2022 Context-driven applications (Assistive services)\u2022 Context-aware assistant (Alexa, Siri etc providing proactive guide to the user) **Healthcare and Early detection:**\u2022 Health sensing (detecting onset of common symptoms through smartwatches and smartphones)",
    "patents": "11,069,334",
    "page_url": "https://cmu.flintbox.com/technologies/9e8b5653-df8f-4f20-8d89-15d5635555b9",
    "llm_summary": "**Summary:**  \nUbicoustics is a sound sensing and classification technology that uses a pre-trained algorithm to detect and classify activities in real-time through microphones in everyday smart devices. It leverages professional sound data for accurate activity labeling, requires no additional hardware, and ensures user privacy by avoiding end-user data collection. The technology is plug-and-play, enabling seamless integration via software updates.\n\n**Applications:**  \n1. Productivity and Maintenance: Reducing workplace interruptions and optimizing equipment utilization through predictive maintenance.  \n2. Guided and Assistive Services: Enhancing context-aware smart assistants (e.g., Alexa, Siri) for proactive user guidance.  \n3. Healthcare and Early Detection: Detecting early symptoms of health issues using smartwatches and smartphones.  \n\n**Problem Solved:**  \nUbicoustics addresses the need for accurate, real-time activity recognition without requiring additional hardware or compromising user privacy, transforming smart devices into more context-aware tools.",
    "llm_teaser": "\"Transform your everyday smart devices into intuitive, context-aware assistants with Ubicoustics\u2014a plug-and-play acoustic activity recognition technology that leverages professional sound data to detect and classify real-time activities, all while ensuring user privacy and requiring no additional hardware.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Electrick: Low-Cost Touch Sensing for Large, Irregular and Rapidly-Prototyped Objects",
    "ip_number": "2017-064",
    "published_date": "Aug 22nd, 2022",
    "ip_description": "Electrick is a low-cost and versatile sensing technique that enables touch input on a wide variety of objects and surfaces, whether small or large, flat or irregular. It is achieved by using electric field tomography in concert with an electrically conductive material, which can be easily and cheaply added to objects and surfaces.Electrick is compatible with commonplace manufacturing methods, such as spray/brush coating, vacuum forming, and casting/molding \u2013 enabling a wide range of possible uses and outputs. Electrick can bring touch interactivity to rapidly fabricated objects, including those that are laser cut or 3D printed. Electrick does not require special chemicals, equipment, or facilities and may be adapted to your own custom formulations. This allows Electrick to be applied to existing objects and surfaces, augmenting them with new touch sensing capabilities.This system can enable new interactive opportunities on a diverse set of objects and surfaces that were previously static. It can accurately track both discrete and continuous touch input under various conditions, materials, shapes, and sizes. It is also robust over time and across users.Example prototypes include touch sensitive game controllers, and car accessories such as steering wheels. By adding electrodes to a carbon-sprayed steering wheel, we can track the position of both hands and detect gestures such as swipes, which a console can translate into a specific command",
    "patents": "10,942,596; CN 201780074894.0",
    "page_url": "https://cmu.flintbox.com/technologies/59c70622-6bcb-4fe5-9b7b-c66f8fe0013a",
    "llm_summary": "**Summary:** Electrick is a low-cost, versatile touch sensing technology that uses electric field tomography and conductive materials to enable touch input on a wide variety of objects and surfaces, regardless of size, shape, or material. It is compatible with common manufacturing methods like spray coating, vacuum forming, and 3D printing, and can accurately track discrete and continuous touch inputs over time and across users.\n\n**Applications:** This technology can be used to create touch-sensitive game controllers, interactive car accessories (e.g., steering wheels), and other rapidly prototyped objects. It is also suitable for adding touch interactivity to existing surfaces and objects in industries like consumer electronics, automotive, and prototyping.\n\n**Problem Solved:** Electrick addresses the challenge of adding touch interactivity to irregular, large, or rapidly prototyped objects without requiring specialized equipment, chemicals, or facilities, enabling new interactive opportunities on previously static surfaces.",
    "llm_teaser": "\"Electrick transforms any surface or object into a touch-sensitive interface with a low-cost, easy-to-apply conductive coating, enabling interactive possibilities for everything from 3D-printed prototypes to everyday items like steering wheels.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Mites: A Ubiquitous Sensing System and Stack",
    "ip_number": "2018-018",
    "published_date": "Aug 22nd, 2022",
    "ip_description": "Smart spaces and the internet of things rely on robust sensing of the environment, achieved by upgrading a space with expensive smart devices that do not talk to one another or tagging devices/rooms with after-market sensors. The latter is more flexible and intelligent but can be socially and aesthetically intrusive. Mites.io create an alternate, general purpose sensing approach that uses a single, highly capable sensor board to indirectly monitor an entire room.\nKey Benefits\nSingle sensor boardcan capture a wide variety of events in a room/confined space (given the extensive sensor dimensions), as opposed to multiple sensors or smart devices.\nReduced network overhead\nPlug & play sensorUses wall powerWiFi enabled -ubiquity, ease of set up, range & high bandwidth.\nUse of machine learning to automatically recognize patterns of sensor activation/events\nNth order sensors\nScaleable-effective and easy if you\u2019re using 3 sensors within a home context or 300 within an enterprise context.\nEnsures user privacyby eliminating the use of camera sensors.End to end encryption support & denaturing data.\nSecure back end for effortless monitoring & maintenance\nRemote sensor controlo Including ability to adjust the sampling frequency/gain of a sensor, updating the firmware across the network\nThere are many applications in IoT sensing- some highlighted applications:\nBuilding/maintenance IoTMechanical health and maintenance of equipmentbased on usage/cycles dataIdentifying & notifying users of malfunctioning equipmentbased on irregular patterns of data/activitySafety & security within facilitybased on motion, temperature among other sensor dimensions. E.g. theft, fire detection.Access controlClimate controlHuman activity across facilityRemote activity monitoringIntegration with workplace toolsto create operational efficiencies by feeding virtual sensors into second or Nth order sensors and capturing higher level inferences.\u00b7Resource conservatione.g. electrical, energy or water usageStock/restock resource schedulingRelevant industries:offices/commercial buildings, government, education, construction, manufacturing, hospitality, oil/gas, property management",
    "patents": "10,436,615",
    "page_url": "https://cmu.flintbox.com/technologies/3ed20286-4aac-4903-b70e-7c2ce1de8d79",
    "llm_summary": "**Summary:** Mites.io offers a versatile sensing system using a single, highly capable sensor board to monitor entire rooms or confined spaces. It leverages machine learning to recognize patterns, ensures user privacy by avoiding cameras, and supports end-to-end encryption. The system is scalable, WiFi-enabled, and allows remote control, including firmware updates and sensor adjustments.  \n\n**Applications:** Building/maintenance IoT, safety and security monitoring, and resource conservation in industries such as offices, manufacturing, hospitality, and property management.  \n\n**Problem Solved:** The technology addresses the inefficiency and intrusiveness of traditional IoT sensing methods by providing a flexible, cost-effective, and privacy-conscious solution for monitoring environments without requiring multiple devices or after-market sensors.",
    "llm_teaser": "\"Revolutionize smart spaces with Mites.io: a single, powerful sensor board that monitors entire rooms, reduces network overhead, ensures privacy, and scales effortlessly from homes to enterprises\u2014all without intrusive cameras or multiple devices.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "OPP-115 Data Set of Privacy Policy Annotations",
    "ip_number": "2021-129",
    "published_date": "Jun 21st, 2021",
    "ip_description": "The OPP-115 Annotation Data Set is a collection of annotations specifying data practices for publicly available privacy policies on the internet.The dataset was created as part of the Usable Privacy Project at Carnegie Mellonhttps://usableprivacy.org/Looking for a non-commercial license? The data set can be accessed for non-commercial purposes:https://usableprivacy.org/dataThese annotations distinguish between 10 different types of data collection and use practices (first party collection/use, third party sharing/collection, user choice/control, user access/edit/deletion, data retention, data security, policy change, do not track, international & specific audiences, other). For each data practice, the annotation scheme further specifies a set of relevant attributes along with different possible values for these attributes.This data set can be used to train algorithms and create modelsS. Wilson, F. Schaub, A.A. Dara, F. Liu, S.K. Cherivirala, P.G. Leon, M.S. Andersen, S. Zimmeck, K.M. Sathyendra, N.C. Russell, T.B. Norton, E. Hovy, J. Reidenberg, and N. Sadeh.The creation and analysis of a website privacy policy corpus.ACL '16: Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, Berlin, Germany, August 2016.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/9900a353-1bac-4d65-b197-d785cdda85bc",
    "llm_summary": "**Summary:**  \nThe OPP-115 Data Set is a collection of annotated privacy policies that specify data practices, distinguishing between 10 types of data collection and use practices. It includes attributes and values for each practice, enabling the training of algorithms and creation of models for analyzing privacy policies. The dataset was developed as part of the Usable Privacy Project at Carnegie Mellon University.\n\n**Applications:**  \n1. Training machine learning algorithms for privacy policy analysis.  \n2. Developing tools to automate the extraction and understanding of data practices in privacy policies.  \n3. Supporting research in privacy policy compliance and usability.\n\n**Problem Solved:**  \nThe dataset addresses the challenge of understanding and analyzing complex privacy policies by providing structured annotations that clarify data collection and use practices, making it easier to study and automate privacy policy analysis.",
    "llm_teaser": "\"Unlock the power of privacy policy analysis with the OPP-115 Data Set, a comprehensive collection of annotated data practices enabling advanced algorithms to decode and model complex privacy policies for enhanced transparency and compliance.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Accessibility Layer (ABLE)",
    "ip_number": "2019-270",
    "published_date": "Aug 27th, 2020",
    "ip_description": "ABLE is a generalized accessibility layer that can be incorporated on top of any voice-based conversational system. Its purpose is to promote human-centered understanding and to make these systems more accessible to a variety of populations, such as seniors, non-native speakers and people who are in the process of multitasking. Though voice-based conversational assistants are becoming increasingly popular, they lack accessibility features, making them difficult to use for some. ABLE implements is a set of algorithms that improve accessibility in order to make systems usable by a wider portion of the population.ABLE widens user base by making systems accessible to a variety of populations, such as seniors, non-native speakers and people who are in the process of multitasking.ABLE Can be incorporated on top of any voice-based conversational system.ABLE adds accessibility features to voice-based conversational assistants.Voice-based servicesVoice-based virtual assistantsMobility on demandSystems accessibilityThough voice-based conversational assistants are becoming increasingly popular, they lack accessibility features, making them difficult to use for some portions of the population; including but not limited to seniors, non-native speakers, some individuals with attention deficit, individuals who are in the process of multitasking, and individuals who are unfamiliar with spoken dialog systems. Examples of issues pertaining to accessibility are understanding synthesized intelligent agent speech, interacting with systems, getting the system to understand and information overload.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/df7ed6ff-90ce-4ec0-9c4c-c688d352f360",
    "llm_summary": "**Summary:**  \nABLE is a generalized accessibility layer designed to enhance voice-based conversational systems by incorporating algorithms that improve usability for diverse populations, including seniors, non-native speakers, and multitasking individuals. It adds accessibility features to make these systems more inclusive and easier to use.\n\n**Applications:**  \n1. Voice-based virtual assistants for personal and professional use.  \n2. Mobility-on-demand services requiring accessible voice interactions.  \n3. Systems aimed at improving accessibility for seniors and non-native speakers.  \n\n**Problem Solved:**  \nABLE addresses the lack of accessibility features in voice-based conversational systems, which makes them difficult for certain populations, such as seniors, non-native speakers, and multitasking individuals, to use effectively.",
    "llm_teaser": "\"ABLE revolutionizes voice-based conversational systems by adding a universal accessibility layer, empowering seniors, non-native speakers, and multitaskers to interact seamlessly with AI assistants, breaking down barriers to understanding and usability.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "OpenFace- Facial Landmark Detection and Facial Expression Analysis Software",
    "ip_number": "2017-163",
    "published_date": "Oct 24th, 2019",
    "ip_description": "OpenFace is a toolkit for building interactive applications based on facial behavior analysis. OpenFace is capable of facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation. The computer vision algorithms which represent the core of OpenFace demonstrate state-of-the-art results in all of the above mentioned tasks. OpenFace is capable of real-time performance, able to run from a simple webcam without any specialist hardware, and allows for easy integration with other applications and devices through a lightweight messaging system.\n\nThree different packages are available for commercial licensing:\n\nOpenFace Light- a light toolkit without advanced model files for facial landmark recognition. For illustrative purposes e.g. source code for very facial landmark detection (smaller training dataset used)\n\nOpenFace 2.0 Landmarks- a robust facial landmark detection and tracking toolkit, including eye gaze estimation/tracking\n\nOpenFace 2.0 Full Suite-a robust facial behavior analysis toolkit, including robust facial landmark detection and tracking, eye gaze estimation/tracking, and facial expression analysis/facial action unit recognition\n\nOpenFace can perform a number of facial analysis tasks:\nFacial Landmark Detection\nFacial Landmark and Headpose tracking\nFacial Action Unit Recognition\nGaze Tracking\nFacial Feature Extraction (aligned faces and HOG features)",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/5c5e7fee-6a24-467b-bb5f-eb2f72119e59",
    "llm_summary": "**Summary:**  \nOpenFace is a state-of-the-art toolkit for facial behavior analysis, capable of real-time facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation. It operates using a simple webcam, requires no specialist hardware, and offers easy integration with other applications through a lightweight messaging system. Three commercial packages are available, ranging from basic landmark detection to a full suite of facial behavior analysis tools.\n\n**Applications:**  \n1. Interactive applications requiring real-time facial analysis (e.g., gaming, virtual reality).  \n2. Human-computer interaction systems for accessibility or user engagement.  \n3. Behavioral research and emotion analysis in psychology or marketing.  \n\n**Problem Solved:**  \nOpenFace addresses the need for accurate, real-time facial behavior analysis without requiring specialized hardware, enabling seamless integration into diverse applications and industries.",
    "llm_teaser": "\"Unlock the power of real-time facial behavior analysis with OpenFace\u2014a state-of-the-art toolkit offering facial landmark detection, gaze tracking, and expression analysis, all seamlessly integrated for interactive applications using just a webcam.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "OpenPose - Realtime Multiperson 2D Keypoint Detection from Video",
    "ip_number": "2017-098",
    "published_date": "Oct 24th, 2019",
    "ip_description": "OpenPose has represented the first real-time multi-person system to jointly detect human body, hand, facial, and foot keypoints (in total 135 keypoints) on single images.It is authored by Gin\u00e9s Hidalgo, Zhe Cao, Tomas Simon, Shih-En Wei, Yaadhav Raaj, Hanbyul Joo, and Yaser Sheikh. It is maintained by Gin\u00e9s Hidalgo and Yaadhav Raaj. OpenPose would not be possible without the CMU Panoptic Studio dataset. We would also like to thank all the people who have helped OpenPose in any way.Library main functionality:Multi-person 15, 18 or 25-keypoint body/foot keypoint estimation, including 6 foot keypoints. Runtime invariant to number of detected people.Multi-person 2x21-keypoint hand keypoint estimation.Multi-person 70-keypoint face keypoint estimation.3D real-time single-person keypoint detection.Calibration toolbox: Estimation of distortion, intrinsic, and extrinsic camera parameters.Single-person tracking for further speedup or visual smoothing.Input: Image, video, webcam, Flir/Point Grey, IP camera, and support to add your own custom input source (e.g., depth camera).Output: Basic image + keypoint display/saving (PNG, JPG, AVI, ...), keypoint saving (JSON, XML, YML, ...), keypoints as array class, and support to add your own custom output code (e.g., some fancy UI).OS: Ubuntu (20, 18, 16, 14), Windows (10, 8), Mac OSX, Nvidia TX2.Hardware compatibility: CUDA (Nvidia GPU), OpenCL (AMD GPU), and non-GPU (CPU-only) versions.Command-line demo for built-in functionality.C++ API and Python API for custom functionality. E.g., adding your custom inputs, pre-processing, post-posprocessing, and output steps.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/b820c21d-8443-4aa2-a49f-8919d93a8740",
    "llm_summary": "**Summary:**  \nOpenPose is a real-time multi-person system capable of detecting 135 keypoints on the human body, hands, face, and feet from single images or video. It supports various input sources (e.g., webcam, IP camera) and outputs keypoints in multiple formats (e.g., JSON, XML). It is compatible with multiple operating systems (Ubuntu, Windows, Mac OSX) and hardware (CUDA, OpenCL, CPU-only).\n\n**Applications:**  \n1. Human pose estimation for fitness and sports analytics.  \n2. Gesture recognition and human-computer interaction in robotics and gaming.  \n3. Surveillance and activity monitoring in security systems.  \n\n**Problem Solved:**  \nOpenPose addresses the challenge of accurately and efficiently detecting and tracking multiple human keypoints in real-time, enabling applications in motion analysis, interaction, and monitoring.",
    "llm_teaser": "\"OpenPose revolutionizes real-time motion analysis by detecting up to 135 keypoints per person\u2014body, hands, face, and feet\u2014enabling unparalleled multi-person tracking and 3D keypoint detection across diverse inputs and platforms.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Seventeen Days Interactive Content",
    "ip_number": "2016-224",
    "published_date": "Oct 24th, 2019",
    "ip_description": "The Seventeen Days Interactive Content is a theory-based interactive film created by Carnegie Mellon University\u2019s Center for Risk Perception and Communication and designed to educate young women about contraception and sexually transmitted infections (STIs). The film presents scenarios involving decisions that young women face in romantic relationships. The film identifies choice points, suggests risk-reduction strategies, and asks viewers to think about what they would do in a similar situation. The film is interactive, allowing viewers to choose what they want to watch. Viewers are given the opportunity to mentally practice how they would respond in hypothetical situations through the frequent use of \u201ccognitive rehearsal.\nThe film centers around a pregnancy scare, presenting educational content through six vignettes, a condom demonstration, and four mini-documentaries. The mini documentaries focus on contraception, STIs and anatomy. They are varied in their approach, including real life stories, dramatized video, interactive features, clinical expertise and mechanical demonstrations.\nThe target audience for this film is sexually active adolescent females aged 14-19.\nSeventeen Days License",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/a8ba9ee5-698a-44c6-bad8-fd02825413f9",
    "llm_summary": "**Summary:**  \nThe Seventeen Days Interactive Content is a theory-based interactive film designed to educate young women aged 14-19 about contraception and sexually transmitted infections (STIs). It uses scenarios, choice points, and cognitive rehearsal to help viewers practice decision-making in romantic relationships. The film includes six vignettes, a condom demonstration, and four mini-documentaries with varied educational approaches.\n\n**Applications:**  \n1. Sexual health education for adolescent females.  \n2. Public health initiatives targeting STI and pregnancy prevention.  \n3. School or community-based programs for youth empowerment and decision-making.  \n\n**Problem Solved:**  \nThe technology addresses the lack of engaging, interactive educational tools to help young women make informed decisions about sexual health and reduce risks related to STIs and unintended pregnancies.",
    "llm_teaser": "\"Empower young women with *Seventeen Days Interactive Content*, a groundbreaking, theory-based interactive film that combines real-life scenarios, cognitive rehearsal, and expert insights to educate and prepare them to make informed decisions about contraception, STIs, and relationships.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Seventeen Days Interactive DVD",
    "ip_number": "2014-014",
    "published_date": "Oct 24th, 2019",
    "ip_description": "The Seventeen Days Interactive DVD is a theory-based interactive film created by Carnegie Mellon University\u2019s Center for Risk Perception and Communication and designed to educate young women about contraception and sexually transmitted infections (STIs). The film presents scenarios involving decisions that young women face in romantic relationships. The film identifies choice points, suggests risk-reduction strategies, and asks viewers to think about what they would do in a similar situation. The film is interactive, allowing viewers to choose what they want to watch. Viewers are given the opportunity to mentally practice how they would respond in hypothetical situations through the frequent use of \u201ccognitive rehearsal.\u201dThe film centers around a pregnancy scare, presenting educational content through six vignettes, a condom demonstration, and four mini-documentaries. The mini documentaries focus on contraception, STIs and anatomy. They are varied in their approach, including real life stories, dramatized video, interactive features, clinical expertise and mechanical demonstrations.The target audience for this video issexually active adolescent females aged 14-19.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/26546c78-067b-4962-87b0-4314c08afbdb",
    "llm_summary": "**Summary:**  \nThe Seventeen Days Interactive DVD is a theory-based interactive film designed to educate young women aged 14-19 about contraception and sexually transmitted infections (STIs). It features six vignettes, a condom demonstration, and four mini-documentaries, using scenarios, cognitive rehearsal, and interactive choices to help viewers practice decision-making in romantic relationships.  \n\n**Applications:**  \n1. Sexual health education for adolescent females.  \n2. School-based or community health programs targeting STI and pregnancy prevention.  \n\n**Problem Solved:**  \nThe DVD addresses the lack of accessible, engaging, and educational resources for young women to learn about contraception, STIs, and decision-making in romantic relationships, helping reduce risks associated with unprotected sex.",
    "llm_teaser": "\"Empower young women with *Seventeen Days*, an interactive DVD that blends real-life scenarios, cognitive rehearsal, and expert insights to help them confidently navigate decisions about contraception, STIs, and relationships\u2014putting control and knowledge in their hands.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "The CMU Multi-PIE Face Database",
    "ip_number": "2009-056",
    "published_date": "Oct 16th, 2019",
    "ip_description": "The CMU Multi-PIE face database contains more than 750,000 images of 337 people recorded in up to four sessions over the span of five months. Subjects were imaged under 15 view points and 19 illumination conditions while displaying a range of facial expressions. In addition, high resolution frontal images were acquired as well. In total, the database contains more than 305 GB of face data. TheContentpage describes the database in more detail.A close relationship exists between the advancement of face recognition algorithms and the availability of face databases varying factors that affect facial appearance in a controlled manner.The PIE database, collected at Carnegie Mellon University in 2000, has been very influential in advancing research in face recognition across pose and illumination. Despite its success the PIE database has several shortcomings: a limited number of subjects, a single recording session and only few expressions captured.To address these issues researchers at Carnegie Mellon University collected the Multi-PIE database. It contains 337 subjects, captured under 15 view points and 19 illumination conditions in four recording sessions for a total of more than 750,000 images.Labels are provided for a total of 6152 images of Multi-PIE. Illumination images were captured by recording 20 images within 0.7 seconds with flashes firing one by one. Due to the minimal subject movement between the different flash images the labels could be copied across all illumination conditions. These are AAM-style labels with between 39 and 68 feature points depending on the pose which were determined manually. Here is an illustration for the points labeled for the frontal view.The collection and structure of the Multi-PIE database along with results of baseline recognition experiments have been described in two research papers:Gross, R., Matthews, I., Cohn, J. F., Kanade, T., & Baker, S. (2008). Multi-PIE. Proceedings of the Eighth IEEE International Conference on Automatic Face and Gesture Recognition.Gross, R., Matthews, I., Cohn, J. F., Kanade, T., & Baker, S. (2009, In press). Multi-PIE. Image and Vision Computing.AvailabilityThe Multi-PIE Face database is available via a license from Carnegie Mellon University for internal research purposes. The size of the database (308 GB) requires that it be shipped on a dedicated hard drive. The cost to license the database includes fees charged by a third party vendor to provide the hard drive containing the database.(Note: The database is too large to download. A USB-attached hard drive that contains the database will be delivered to your 'Shipping Address'.)Note that you may alternatively license the Multi-PIE database in combination with theFace-in-Actiondatabase for a combined price. Both databases will be provided on the same hard drive. Here's theFace-in-Action web page.FAQAre the labels provided for the high resolution frontal images (the ones that are 6.3 megapixel)?Labels are only provided for the lower resolution images which were taken inside the 3D room.Are there high-resolution frontal images provided for all 337 subjects?Yes, the DB contains high-resolution frontal images for all subjects.Can the database just be downloaded?Since the dataset is so large (308 GB), it has to be shipped on a dedicated USB-attached hard drive.Are there high-resolution frontal images provided for all 337 subjects?Yes, the DB contains high-resolution frontal images for all subjects.What file format are the images and the labels?Images are stored as either JPG (for the highres images) or PNG (multi-view images). Additional information is available in text files (subject info) or in the directory structure/file name (expression, illumination, camera view). The feature points are stored in \u201c.mat\u201d files.Payment by credit card can be made after agreeing to the Multi-PIE Face database license agreement. Your order will be shipped within one week of payment confirmed by your credit card. Please allow 5-7 days for delivery.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/67027840-27d5-4570-86dd-ad4715ef3c09",
    "llm_summary": "**Summary:**  \nThe CMU Multi-PIE Face Database contains over 750,000 images of 337 subjects captured across 15 viewpoints, 19 illumination conditions, and four recording sessions, totaling 305 GB of data. It includes high-resolution frontal images and labeled feature points for 6,152 images, supporting advanced face recognition research.\n\n**Applications:**  \n1. Development and testing of face recognition algorithms.  \n2. Research on facial expression analysis and pose-invariant recognition.  \n3. Applications in biometrics, security, and human-computer interaction.  \n\n**Problem Solved:**  \nThe database addresses limitations of earlier face datasets by providing a larger, more diverse dataset with multiple sessions, expressions, and controlled variations in pose and illumination, enabling more robust and accurate face recognition research.",
    "llm_teaser": "\"Revolutionize face recognition research with the CMU Multi-PIE Face Database: over 750,000 images of 337 subjects captured across 15 viewpoints, 19 illuminations, and multiple expressions, offering unparalleled diversity and precision for advancing AI-driven facial analysis.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "FiA \"Face-in-Action\" Dataset",
    "ip_number": "2011-031",
    "published_date": "Oct 14th, 2019",
    "ip_description": "Our team has collected a face video database named the CMU Face In Action (FIA) database. This database consists of 20-second videos of face data from 180 participants mimicking a passport checking scenario. The data is captured by six synchronized cameras from three different angles, with an 8-mm and 4-mm focal-length for each of these angles. We performed the collection in both a controlled, indoor environment and an open, outdoor environment for each participant. Our data collection was taken in three sessions over a period of ten months. We aimed for a three month separation between sessions for each participant. We expect the database to be useful for analysis and modeling of faces and gestures.The CMU FIA database, with imaging variations such as pose, illumination, expression, aging, and etc. is beneficial to the task of recognizing human faces. The database is especially helpful in relation to pose and face gesture variation, which is most difficult to model. This database consists of 20-second videos of face data from 180 participants mimicking a passport checking scenario. The data is captured by six synchronized cameras from three different angles, with an 8-mm and 4-mm focal-length for each of these angles. The image collection was performed in both a controlled, indoor environment and an open, outdoor environment for each participant. The data collection was taken in three sessions over a period of ten months, with a goal of a three month separation between sessions for each participant.Given the types of image variation, the following uses are suggested for CMU FIA:Video-based face recognitionPose invariant face recognitionThree-dimensional face reconstruction from multiple views or from a video sequenceFace recognition with respect to image resolutionOutdoor illumination invariant face recognitionFace recognition over periods of timeFace and facial gesture modeling and analysis",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/cbcfab1b-d4fb-4a6c-97bc-3b630027c499",
    "llm_summary": "**Summary:**  \nThe CMU Face In Action (FIA) database is a collection of 20-second face videos from 180 participants, captured in both indoor and outdoor environments using six synchronized cameras from three angles. The dataset includes variations in pose, illumination, expression, aging, and resolution, making it valuable for face and gesture analysis. Data was collected over ten months in three sessions per participant, with three-month intervals between sessions.\n\n**Applications:**  \n- Video-based and pose-invariant face recognition  \n- Three-dimensional face reconstruction from multiple views or video sequences  \n- Face recognition under varying illumination, resolution, and over time  \n\n**Problem Solved:**  \nThe FIA database addresses the challenge of modeling and recognizing human faces under diverse conditions, particularly focusing on pose and facial gesture variations, which are difficult to capture and analyze.",
    "llm_teaser": "\"Unlock the future of face recognition with the CMU Face-in-Action (FIA) dataset: a comprehensive, multi-angle, multi-session video database capturing 180 participants in diverse environments, enabling breakthroughs in pose-invariant, gesture-aware, and time-resilient facial analysis.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Human milk sugars with lipid nanoparticle formulation",
    "ip_number": "2023-273",
    "published_date": "Jan 7th, 2025",
    "ip_description": "Key HighlightsThe technology incorporates human milk oligosaccharides (HMOs) in lipid nanoparticle (LNP)-based RNA therapies to develop a new biocompatible compound that leverages HMOs known for their role in supporting infant gut health.The technology addresses challenges in LNP-based RNA therapy, boosting delivery efficacy while mitigating immune reactions that often lead to pain, inflammation, and disruptions in mRNA translation, thus potentially improving overall treatment outcomes.Beyond COVID-19 vaccines, this technology has the potential to broaden the scope of RNA therapeutics for various medical conditions by improving delivery and circumventing issues linked to decreased efficacy in the presence of inflammation, thereby offering hope for treating diseases with dysregulated proteins.BenefitThe technology\u2019s capacity to significantly enhance RNA delivery promises a substantial improvement in therapeutic outcomes. By fortifying the protection and precision of RNA payloads, it holds the potential to magnify the efficacy of treatments. Additionally, the technology's adeptness in modulating immune responses, attributed to the inclusion of human milk oligosaccharides (HMOs), is a crucial advantage.This modulation capability not only augments safety profiles by curbing adverse immune reactions often linked with LNPs but also mitigates inflammation, fostering a more tolerable and safer therapeutic experience for patients. Its versatility across various RNA therapies further elevates its significance, opening doors to a wider array of applications and potentially transforming the treatment landscape for diverse diseases. Moreover, the utilization of HMOs from human milk bolsters the therapy's biocompatibility, potentially minimizing the risk of adverse reactions and enhancing patient tolerance, marking a pivotal step towards safer and more effective RNA-based interventions.Market ApplicationVaccines: Expanding the effectiveness of RNA vaccines beyond COVID-19 by enhancing their delivery and reducing immune reactions could revolutionize vaccine development against a wide array of infectious diseases.Gene Therapy: Targeted delivery of RNA could be pivotal in treating genetic disorders by modulating the expression of specific genes, offering potential solutions for conditions currently lacking effective treatments.Cancer Therapeutics: RNA therapies have shown promise in cancer treatment by targeting specific tumor-related proteins 1. Enhancing RNA delivery and efficacy while minimizing immune reactions could significantly improve cancer therapies.Inflammatory Disorders: The ability of human milk oligosaccharides (HMOs) to inhibit proinflammatory responses could be harnessed for treating diseases characterized by inflammation, such as autoimmune disorders.Rare Diseases: Many rare diseases stem from dysregulated proteins. This technology offers a platform to tailor RNA therapies for such conditions where specific proteins are upregulated or downregulated.Neurological Disorders: RNA therapies have potential applications in neurological disorders where protein dysregulation is a key factor. Improved delivery methods could enhance their efficacy in treating conditions like Alzheimer's or Parkinson's disease.Metabolic Disorders: Conditions like diabetes or metabolic syndromes could benefit from RNA therapies targeting proteins involved in metabolic pathways. Enhanced delivery might improve treatment outcomes.Personalized Medicine: The adaptability of RNA therapies allows for personalized treatments tailored to an individual's genetic makeup, potentially transforming the landscape of precision medicine.Cryopreservation: the same properties that stabilize LNPs for mRNA delivery can also protect cells during the freezing and thawing processes needed to preserve cells at very low temperatures. HMOs can inhibit the formation of ice crystals.OtherIPApplication No.: PCT/US2024/035257Type: International",
    "patents": "PCT/US2024/035257",
    "page_url": "https://cmu.flintbox.com/technologies/ac1cea94-bc85-4eb2-a642-d0d4fdf28a6e",
    "llm_summary": "**Summary:** This technology integrates human milk oligosaccharides (HMOs) into lipid nanoparticle (LNP)-based RNA therapies to enhance delivery efficacy and reduce immune reactions. It improves RNA payload protection, modulates immune responses, and increases biocompatibility, offering potential for safer and more effective RNA-based treatments across various medical conditions.  \n\n**Applications:** Key applications include RNA vaccines, gene therapy for genetic disorders, cancer therapeutics, and treatments for inflammatory, neurological, and metabolic disorders.  \n\n**Problem Solved:** The technology addresses challenges in LNP-based RNA therapy, such as immune reactions, inflammation, and reduced efficacy, by leveraging HMOs to improve delivery and safety profiles.",
    "llm_teaser": "\"Revolutionizing RNA therapies with human milk sugars in lipid nanoparticles, this breakthrough enhances delivery, reduces immune reactions, and unlocks safer, more effective treatments for diseases from cancer to rare genetic disorders.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "3D MXene Network on Porous Backbones for High-Performance Energy Storage",
    "ip_number": "2023-224",
    "published_date": "Nov 11th, 2024",
    "ip_description": "This invention addresses a major challenge in utilizing two-dimensional (2D) transition metal carbides (MXenes) by introducing a hybrid material system that assembles MXenes in a three-dimensional (3D)network without restacking, which typically degrades their performance.The approach involves creating a 3D MXene network on a porous ceramic backbone.The porous backbone dictates the 3Darchitecture, provides mechanical strength, and enables gas/liquid permeability.The fabrication begins withfreeze-castingto produce a porous silica backbone with controlled porositydistribution. Next, an MXene dispersion infiltrates the backbone using capillary flow, conformally coatingthe pore walls. After drying, an interconnected 3D MXene network is formed on the porous backbone.Multiple infiltration cycles can create layers of different materials, such as MXene and carbon nanotubes.The resultingMXene-infiltrated porous silica (MX-PS) system exhibits high electricalconductivity, which can be tuned by adjusting the MXene concentration, infiltration cycles, and porosity distribution. Asa demonstration, sandwich-type supercapacitors with MX-PS electrodes produced excellent areal capacitance and energy density with a small added MXene mass. The design approach allows for precise tuning of the material's structural characteristics and composition, resulting in improvedmechanical robustness, controlled fluid permeability, and tailored electrochemical performance. These capabilities position this technology as a viable solution for diverse applications in the energy storage domain.1.Exceptional electrochemical performance and conductivity: The MX-PS system exhibitsoutstanding areal capacitance, energy density, and high conductivity, making it suitable for high-performance energy storage and other applications. The interconnected network of MXeneswithin the porous backbone allows for efficient charge transport. This is crucial for applicationslike supercapacitors, batteries, and electronic components.2.Tunable properties: The conductivity and porosity of the MX-PS system can be controlled byadjusting the MXene concentration, number of infiltration cycles, and porosity distribution of thebackbone, enabling tailoring of properties for specific applications.3.Versatility: The approach can be extended to other 2D materials (e.g., graphene, carbonnanotubes) and backbone materials (ceramics, metals, polymers), enabling the fabrication ofvarious multi-material structures for diverse applications.4.Mechanical strength and porosity: The porous backbone provides mechanical robustness andcontrolled porosity, facilitating gas/liquid permeability and structural integrity.5.Scalability and Reproducibility: The fabrication approach is reproducible and scalable, makingit suitable for large-scale production.6.Incorporation of Additional Materials: The ability to integrate other materials into the backbone or MXene itself allows for increased functionality. Conductive polymers in the backbone can improve battery performance, whereas catalytic sites within MXenes can increase reaction efficiency.Potential ApplicationsEnergy storage devices: This material system's high conductivity and excellent performancemake it suitable for energy storage devices such as supercapacitors and batteries. Theinterconnected 3D network of 2D nanomaterials can increase these devices' charge storagecapacity and power density. The MXene-infiltrated porous silica (MX-PS) system demonstratesexcellent performance as electrodes in sandwich-type supercapacitors, producing high arealCatalysis: Due to its large surface area and conductivity, the 3D MXene network on a porousbackbone can be used as a high-performance catalyst.Water Desalination: The porous structure and conductive MXene network make the MX-PSsystem promising for applications such as capacitive deionization for water desalination. TheMXene's high surface area and tunable pore size in the backbone can facilitate selective iontransport, allowing for clean water production from saline solutions.Fuel cells: The 3D MXene network's high conductivity and porosity make it an efficient electrodematerial for fuel cells.Sensors: The MX-PS system's unique structure and properties can be used to develop a varietyof sensors, including gas sensors and biosensors. The 3D network can enhance the sensor\u2019ssensitivity and response time.Electromagnetic Interference Shielding: The interconnected 3D network of conductive 2Dmaterials can effectively shield electromagnetic interference, which is critical in electronicdevices.Conductive Polymers and Ceramics: The approach can be used to fabricate conductiveMulti-Material Structures: The technology can be used to fabricate multi-material structures,such as metal-ceramic hybrids or metal-polymer hybrids. These structures can have tailoredproperties for specific applications.Conductive Films and Transparent Electrodes: The 3D MXene network's high conductivitymakes it a potential candidate for transparent conductive films. These films can be used invarious electronic applications, such as touch screens, solar cells, and organic light-emittingdiodes (OLEDs).",
    "patents": "PCT/US2024/030282",
    "page_url": "https://cmu.flintbox.com/technologies/62678cad-8775-479d-8963-b8b8a1ece46f",
    "llm_summary": "**Summary:** This technology introduces a hybrid material system that assembles 2D MXenes into a 3D network on a porous ceramic backbone, preventing restacking and enhancing performance. The system offers tunable conductivity, mechanical strength, and controlled porosity, making it scalable and versatile for energy storage and other applications.  \n\n**Applications:** Energy storage devices (supercapacitors, batteries), water desalination (capacitive deionization), and catalysis.  \n\n**Problem Solved:** It addresses the challenge of MXene restacking, which degrades performance, by creating a 3D interconnected network that improves conductivity, mechanical robustness, and electrochemical performance.",
    "llm_teaser": "\"Revolutionize energy storage with a 3D MXene network on porous backbones, delivering unmatched conductivity, tunable performance, and scalable fabrication for supercapacitors, batteries, and beyond.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "DocuScope\u2122 Corpus Analysis - Computer-Aided Rhetorical Analysis and Dictionary Building Tool (v.3.1.0)",
    "ip_number": "CMU 2019-148",
    "published_date": "Feb 22nd, 2024",
    "ip_description": "DocuScope\u2122 is a dictionary-based text analysis and visualization tool that supports the rhetorical analysis of texts from both a quantitative and qualitative perspective using a home-grown dictionary. DocuScope\u2122 Corpus Analysis is the latest version of the original DocuScope\u2122 (1998). DocuScope\u2122 Corpus Analysis supports most of the features supported by the original version. This DocuScope was initially published under the name DocuScope\u2122 Global, but has been renamed to DocuScope\u2122 Corpus Analysis.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/5a9cc57f-24f0-4725-b55c-0552b2eb8dae",
    "llm_summary": "**Summary:**  \nDocuScope\u2122 Corpus Analysis (v.3.1.0) is a dictionary-based text analysis and visualization tool designed for rhetorical analysis, offering both quantitative and qualitative insights. It builds on the original DocuScope\u2122 (1998) and retains most of its features, now rebranded from DocuScope\u2122 Global to DocuScope\u2122 Corpus Analysis.\n\n**Applications:**  \n1. Rhetorical analysis in academic research and writing.  \n2. Textual analysis in linguistics and communication studies.  \n3. Visualization and interpretation of large text corpora.  \n\n**Problem Solved:**  \nDocuScope\u2122 Corpus Analysis addresses the challenge of analyzing and visualizing the rhetorical structure of texts, enabling users to gain deeper insights into textual patterns and communication strategies.",
    "llm_teaser": "\"Unlock deeper insights into text with DocuScope\u2122 Corpus Analysis, the advanced dictionary-based tool that combines quantitative and qualitative rhetorical analysis to reveal patterns and meaning in your documents like never before.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Modular DNA Nanoshells for Cell Encapsulation and Ruggedization",
    "ip_number": "2023-063",
    "published_date": "Dec 22nd, 2023",
    "ip_description": "The developed technology uses DNA origami nanorods to form a protective shell around living cells, targeting the cell-surface glycocalyx. This nanoshell provides essential protection to cells during harsh experimental and therapeutic conditions, such as osmotic imbalance and centrifugal forces.The developed technology is modular and programmable, allowing fine control over the layering and density of the nanorods deposited on the cellular plasma membrane.The nanoshell also modulates the biomechanical properties of cells by enhancing membrane stiffness and reducing lipid fluidity, contributing to increased cell viability and resilience against mechanical stressors.The developed technology\u2019s primary strength lies in its ability to offer precise control and modularity which enables fine tuning the layering and density of DNA origami nanorods on cellular plasma membranes, ensuring tailored protection and manipulation of cells for specific applications and environments. Another standout feature is its ability to modulate cell biomechanics by enhancing membrane stiffness and reducing lipid fluidity, thereby bolstering cell viability and resilience against mechanical stressors. Moreover, the nanoshell's biocompatibility and biodegradability under physiological conditions ensure its safety within biological systems, minimizing potential long-term adverse effects. Its versatility and adaptability render it suitable for a wide array of applications in therapeutic and bioengineering domains, ranging from regenerative medicine to biomedical research. Additionally, the nanoshell's capacity to integrate seamlessly with biomolecules and biosensors offers avenues for longer-term presentation and controlled release of therapeutic agents or signaling molecules, enhancing its utility across various biomedical contexts.Potential ApplicationsCell Therapy and Regenerative Medicine:The developed technology can protect cells during transplantation and enhance their viability and functionality, thereby improving the efficacy of cell-based therapies such as regenerative medicine to repair damaged tissues and organs.Drug Delivery Systems:The nanoshells can serve as carriers for delivering therapeutic agents, such as drugs or biomolecules, to specific target cells or tissues for controlled release of payloads, enabling precise modulation of drug delivery kinetics and enhancing therapeutic outcomes.Biological Imaging and Sensing:The developed technology can be integrated with biosensors and imaging agents to facilitate the visualization and detection of biological molecules or cellular processes.Bioelectronics and Biosensors:The developed technology can be conjugated with biomolecules and integrated into bioelectronic devices and biosensing platforms for development of sensitive and selective sensors for detecting biological analytes, ranging from biomarkers to pathogens.Food and Agriculture:The developed technology can be utilized in food preservation and agricultural practices to protect sensitive food ingredients or agricultural products from degradation, extending shelf life and improving product quality.",
    "patents": "Provisional Application No. : 63/404,379 / Utility Application No.: 18/462,634",
    "page_url": "https://cmu.flintbox.com/technologies/730e0f31-bd31-440c-ad32-d5c40fa92a55",
    "llm_summary": "**Summary:**  \nThe technology uses modular DNA origami nanorods to create a protective nanoshell around living cells, enhancing their resilience against mechanical stressors and harsh conditions. It allows precise control over layering and density, modulates cell biomechanics, and is biocompatible and biodegradable, making it suitable for diverse biomedical applications.  \n\n**Applications:**  \n1. Cell therapy and regenerative medicine for improved cell viability and functionality.  \n2. Drug delivery systems for controlled release of therapeutic agents.  \n3. Biological imaging, sensing, and bioelectronics for detecting biomarkers or pathogens.  \n\n**Problem Solved:**  \nThe technology addresses the challenge of protecting cells during harsh experimental and therapeutic conditions, such as osmotic imbalance and centrifugal forces, while enhancing their viability and resilience.",
    "llm_teaser": "\"Revolutionize cell therapy and beyond with modular DNA nanoshells\u2014programmable, biocompatible shields that enhance cell resilience, viability, and functionality under harsh conditions, enabling breakthroughs in regenerative medicine, drug delivery, and bioengineering.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Reactive condensation particle counter for the detection of trace atmospheric gases",
    "ip_number": "2023-155",
    "published_date": "Dec 22nd, 2023",
    "ip_description": "This technology presents a significant advancement in the field of atmospheric gas detection, offering a precise, rapid, and cost-effective method for measuring trace gas concentrations in the atmosphere. By utilizing a unique reactive gas that quickly forms detectable particles upon contact with targeted gases, it enables swift and accurate monitoring of atmospheric conditions. Originally developed for sulfuric acid vapor detection, its versatile design allows adaptation for a wide variety of atmospheric gases, enhancing its applicability across different environmental and research settings. The device's portability and the use of a conventional condensation particle counter for detection simplify its operation, making it accessible and user-friendly. This technology not only reduces the cost and technical barriers associated with traditional methods like chemical ionization mass spectrometry but also improves real-time analysis capabilities, significantly benefiting environmental monitoring and air quality assessment efforts.\n\nKey Highlights\nPrecision Detection: Offers high precision in detecting trace amounts of atmospheric gases, ensuring accurate measurements of even the most minute concentrations.\nRapid Reaction Technology: Utilizes a unique gas that reacts quickly with targeted reactive gases, forming detectable particles swiftly, which enhances the speed of detection and analysis.\nCost-Effective: Provides a less expensive alternative to traditional methods like chemical ionization mass spectrometry, making advanced detection technologies more accessible to a broader range of users and applications.\nPortability: Due to its design and operation principle, this device is more portable than many conventional gas detection systems, facilitating easy transport and use in various field settings.\nVersatility in Application: While initially developed for measuring sulfuric acid vapor concentrations, the technology's adaptable nature allows for potential use in detecting a wide range of atmospheric gases by selecting appropriate reactive gases.\nEase of Use: The use of a conventional condensation particle counter for the final detection step simplifies the operational process, making it more user-friendly and less technically demanding than methods requiring specialized knowledge.\nEnvironmental Monitoring Enhancement: Offers an improved tool for environmental monitoring, crucial for air quality assessment, pollution tracking, and research in atmospheric sciences.\nReal-Time Analysis Capability: The rapid reaction and detection process potentially allows for real-time monitoring and analysis of atmospheric gas concentrations, providing immediate data for environmental health and safety applications.\n\nPotential Applications\nEnvironmental Monitoring: For tracking air quality, detecting pollution levels, and monitoring atmospheric changes. It's crucial for regulatory agencies and environmental protection organizations.\nPublic Health: To study the impact of air pollution on human health, helping public health organizations and researchers understand and mitigate risks associated with air quality.\nIndustrial Safety: In industries where specific gases may pose a risk of explosion or health hazards, such as chemical manufacturing, oil and gas, and mining, for detecting leaks and ensuring workplace safety.\nResearch and Development: Academic and industrial research institutions could use this technology for atmospheric sciences, environmental chemistry, and materials science research, especially in studies related to climate change and air pollution.\nAgriculture: For monitoring greenhouse gases and optimizing conditions within controlled environments like greenhouses, contributing to sustainable farming practices.\nUrban Planning and Smart Cities: To integrate into smart city infrastructure for real-time air quality monitoring, helping to inform policy decisions and improve urban living conditions.\nAutomotive and Transportation: For emissions testing and development of cleaner, more efficient engine technologies. It could also be used in monitoring air quality in and around transportation hubs and inside vehicles.\nDefense and Security: For detecting chemical warfare agents or toxic industrial chemicals as part of national security measures and battlefield safety.\nConsumer Products: Development of portable air quality monitoring devices for personal use, empowering individuals to understand their exposure to potentially harmful atmospheric conditions.\nAerospace and Aviation: For monitoring cabin air quality and ensuring the safety and comfort of passengers and crew, as well as for environmental research related to the upper atmosphere.",
    "patents": "2023-155-01, US, 63/445,333 Provisional (Converted to NPPA)",
    "page_url": "https://cmu.flintbox.com/technologies/e15a2310-dee5-49d6-a8b0-72b34ecf26d5",
    "llm_summary": "**Summary:** This technology is a reactive condensation particle counter that provides precise, rapid, and cost-effective detection of trace atmospheric gases. It uses a unique reactive gas to form detectable particles quickly, enabling real-time analysis and portability, while simplifying operation with a conventional condensation particle counter. Its versatility allows adaptation for various gases beyond its initial use for sulfuric acid vapor detection.  \n\n**Applications:** Key applications include environmental monitoring for air quality and pollution tracking, industrial safety for detecting hazardous gases, and research in atmospheric sciences and climate change studies.  \n\n**Problem Solved:** It addresses the high cost, technical complexity, and lack of portability associated with traditional gas detection methods like chemical ionization mass spectrometry, offering a more accessible and efficient solution for real-time atmospheric gas monitoring.",
    "llm_teaser": "\"Revolutionize atmospheric gas detection with a portable, cost-effective reactive condensation particle counter that delivers precise, real-time monitoring of trace gases, transforming environmental and industrial safety applications.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Post-synthetic modification of synthetic and natural RNA with ATRP initiators or vinyl groups by using functional acylation reagents.",
    "ip_number": "2023-087",
    "published_date": "Dec 22nd, 2023",
    "ip_description": "Key Highlights\nHybrid Material Synthesis: Combines the properties of nucleic acids (DNA and RNA) with synthetic polymers, creating materials with blended characteristics for enhanced functionality.\nOvercoming Synthesis Challenges: Addresses the limited reactivity of nucleic acids by utilizing clickable handles (e.g., -NH2, -COOH, -alkyne) for coupling reactions, simplifying the synthesis process of these hybrid materials.\nInnovative Functionalization Technique: Introduces a novel approach for the post-synthetic modification of RNA, using acylation reagents equipped with ATRP initiators or vinyl groups. This method does not rely on solid-phase synthesis, enabling direct and covalent modifications.\nUniversal and Versatile Application: The developed technology can modify any RNA without the need for prior design or synthesis of the RNA substrates, making it universally applicable and offering a broader choice of RNA substrates for modification.\nBroadening Biomaterial Applications: The resulting RNA, post-acylation, can serve as an initiator or monomer for creating novel RNA-based biomaterials, opening new avenues in the development of biomaterials with specific and desirable properties.\n\nThe technology introduced represents a groundbreaking advancement in the synthesis of nucleic acid-synthetic polymer hybrid materials, overcoming traditional challenges associated with the limited reactivity of nucleic acids. By leveraging novel acylation reagents equipped with ATRP initiators or vinyl groups, this method enables the direct and covalent modification of RNA in a post-synthetic manner, without relying on solid-phase synthesis. This innovation not only simplifies the synthesis process but also expands the versatility and applicability of the technology, allowing for the use of any RNA as a substrate. Consequently, it paves the way for the creation of novel RNA-based biomaterials, offering significant potential for the development of biomaterials with customized properties for various applications. This universal and versatile approach marks a significant step forward in material science, broadening the scope of possibilities for RNA functionalization and the design of next-generation biomaterials.\n\nPotential Applications\nBiomedical Engineering:\nDrug Delivery Systems: Designing RNA-based carriers that can specifically target cells and release therapeutic agents in a controlled manner.\nTissue Engineering: Creating scaffolds that support cell growth and tissue formation, potentially incorporating RNA sequences that promote healing or regeneration.\nPharmaceuticals:\nGene Therapy: Utilizing RNA hybrids to develop safer and more efficient vectors for delivering genetic material into cells to correct genetic disorders.\nVaccine Development: Designing novel adjuvants or delivery systems for RNA vaccines, enhancing their stability and effectiveness.\nBiosensing and Diagnostics:\nBiosensors: Developing sensitive and selective biosensors for the detection of biomolecules or pathogens, leveraging the specific binding capabilities of RNA.\nDiagnostic Tools: Creating advanced platforms for the rapid and accurate diagnosis of diseases, including genetic and infectious diseases.\nMaterials Science:\nSmart Materials: Engineering materials that can respond to environmental stimuli (e.g., temperature, pH) in a predictable manner, useful in various applications from packaging to responsive textiles.\nBiodegradable Materials: Producing environmentally friendly materials that degrade into non-toxic substances, reducing pollution and waste.\nNanotechnology:\nNanocarriers: Fabricating nanoscale delivery systems for drugs, genes, or other therapeutic agents, offering targeted delivery and reduced side effects.\nNanostructured Materials: Creating materials with enhanced mechanical, electrical, or optical properties for use in electronics, optics, and other fields.\nResearch and Development:\nMolecular Biology Tools: Providing new tools for the study of RNA function and protein expression, facilitating advances in biology and medicine.\nSynthetic Biology: Enabling the design and construction of new biological parts, devices, and systems, or the redesign of existing, natural biological systems for useful purposes.",
    "patents": "2023-087-01, US, 63/415,682 Provisional (Expired) 2023-087-03, NA, PCT/US2023/076789 PCT (Active)",
    "page_url": "https://cmu.flintbox.com/technologies/cadffbe4-7260-4e86-b360-e6e3ee91dc6a",
    "llm_summary": "**Summary:** This technology enables the post-synthetic modification of RNA using acylation reagents with ATRP initiators or vinyl groups, allowing direct and covalent functionalization without solid-phase synthesis. It simplifies the creation of nucleic acid-synthetic polymer hybrid materials and is universally applicable to any RNA substrate, broadening the potential for novel RNA-based biomaterials.  \n\n**Applications:** Key applications include biomedical engineering (drug delivery, tissue engineering), pharmaceuticals (gene therapy, vaccine development), and biosensing (diagnostics, biosensors).  \n\n**Problem Solved:** It addresses the limited reactivity of nucleic acids by providing a versatile and universal method for RNA functionalization, overcoming challenges in synthesizing hybrid materials.",
    "llm_teaser": "\"Revolutionize biomaterial design with a universal, post-synthetic RNA modification technology that enables direct covalent functionalization using ATRP initiators or vinyl groups, unlocking limitless possibilities for RNA-based drug delivery, diagnostics, and smart materials.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Stress-and-temperature-induced drift compensation for high-precision inertial measurement unit using deep neural network Based machine learning",
    "ip_number": "2021-125",
    "published_date": "Dec 22nd, 2023",
    "ip_description": "The stress-and-temperature-induced drift compensation technique addresses long-term scale factor and bias drift of inertial measurement units corresponding to environmental changes and packaging interaction with the measurement unit.\n\nThe stress-and-temperature-induced drift compensation technique incorporates a large set of on-chip environmental sensors and inertial sensor(s) data to calibrate the machine learning compensation algorithm to alleviate and even eliminate environmental effects and/or packaging effects on the long-term performance of inertial measurement unit. This technique can be used with other MEMS-based sensors, especially inertial sensors in other technologies to make any sensor better.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/71dbeccc-29e8-4fe4-9123-f5d6cb3e35a2",
    "llm_summary": "**Summary:** This technology uses a deep neural network-based machine learning algorithm to compensate for stress-and-temperature-induced drift in high-precision inertial measurement units (IMUs). It leverages on-chip environmental sensors and inertial sensor data to mitigate environmental and packaging effects, improving long-term performance. The technique is adaptable to other MEMS-based sensors, particularly inertial sensors.\n\n**Applications:** Aerospace and defense systems, autonomous vehicles, and precision navigation systems.\n\n**Problem Solved:** It addresses long-term scale factor and bias drift in IMUs caused by environmental changes and packaging interactions, ensuring consistent and accurate performance over time.",
    "llm_teaser": "\"Revolutionize inertial measurement precision with a deep neural network-based technique that eliminates stress-and-temperature-induced drift, ensuring long-term accuracy even in harsh environments.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "3D Printed, Biodegradable Hydrogel Actuators with Shape Morphing Capability for Soft Robotics",
    "ip_number": "2022-255",
    "published_date": "Dec 22nd, 2023",
    "ip_description": "We introduce soft actuators and soft robots that are biocompatible, biodegradable, reconfigurable with shape morphing capability and their associated fabrication process based on hydrogel 3-dimensional (3D) printing. The soft robot can be printed using existing hardware for Freeform Reversible Embedding of Suspended Hydrogels with a modified fabrication protocol, which ensures proper layer-to-layer bonding between 3D printed hydrogel filaments. This fabrication protocol creates water-tight compartments within printed hydrogel structures that enable consistent and reliable hydraulic actuation for the soft robot.\n\nSoft robots made with this process possess a unique combination of biocompatibility, biodegradability, reconfigurability and shape morphing capability. Specifically, the 3D printing bio-ink materials are naturally sourced from plants and algae with proven biocompatibility. The chemicals used in the 3D printing process are naturally present natural environments. Our experimental results show that soft robots made with this process are biodegradable with controlled degradation speed. The crosslinking method used in the 3D printing process is reversible using environment-friendly chemicals. Using this reversibility, the mechanical properties of the actuators can be varied based on the composition of the internal working fluid, and soft robots can be assembled post-printing by attaching individually actuatable soft actuators. Additionally, the actuation geometry of the soft robots can be locally modified post-fabrication using the same technique for different applications.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/cab74a7a-8e68-463b-bb50-88c320eb4d81",
    "llm_summary": "**Summary:** This technology introduces 3D-printed, biodegradable hydrogel actuators with shape morphing capabilities for soft robotics. The fabrication process uses biocompatible, plant- and algae-based materials, enabling water-tight compartments for reliable hydraulic actuation. The actuators are reconfigurable, biodegradable with controlled degradation, and their mechanical properties can be adjusted post-printing using environmentally friendly methods.  \n\n**Applications:**  \n1. Soft robotics for medical devices and implants due to biocompatibility and biodegradability.  \n2. Environmental monitoring or cleanup tools that degrade naturally after use.  \n3. Reconfigurable robotics for adaptive applications in industrial or research settings.  \n\n**Problem Solved:** This technology addresses the need for sustainable, biocompatible, and reconfigurable soft robotics by providing a biodegradable, 3D-printed solution with shape morphing capabilities and controlled degradation.",
    "llm_teaser": "\"Revolutionizing soft robotics with 3D-printed, biodegradable hydrogel actuators that combine biocompatibility, reconfigurability, and shape-morphing capabilities, all powered by eco-friendly, plant-based materials and reversible crosslinking for sustainable, customizable applications.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Hierarchically porous ionomer layer for use as an electrochemical catalyst support",
    "ip_number": "2023-137",
    "published_date": "Dec 21st, 2023",
    "ip_description": "Key HighlightsLow-Cost Fabrication Method: The technology employs a low-cost method that is easily scalable, making it accessible for widespread application in electrochemical industries.Open Pore-Structure: The fabrication of a porous ionomer layer with an open pore-structure enhances its functionality as an ion-conducting catalyst support, crucial for various electrochemical applications.Versatile Catalyst Coating Methods: It supports multiple methods for applying the catalyst onto the surface of the ionomer network, including chemical vapor deposition, atomic layer deposition, and catalyst ink imbibition. This versatility allows for flexibility in application based on specific needs or constraints.Enhanced Catalyst Deposition: The hierarchical pore structure, with pores ranging from 0.5 \u2013 5 \u03bcm, ensures ease of access for the catalyst vapor during deposition and provides a large surface area for effective catalyst contact. This could lead to more efficient and uniform catalyst coatings.Potential for Improved Electrochemical Performance: The combination of an open pore-structure and hierarchical arrangement of the pores is likely to facilitate better ion conduction and enhance the overall performance of the electrochemical applications it is used in.The technology outlined presents a significant advancement in the field of electrochemical applications through the development of a low-cost, easily scalable method for fabricing a porous ionomer layer with an open pore-structure. This innovation not only allows for efficient ion conduction but also supports versatile catalyst coating methods such as chemical vapor deposition, atomic layer deposition, and catalyst ink imbibition. The hierarchical arrangement of pores ranging from 0.5 \u2013 5 \u03bcm enhances catalyst deposition, offering ease of access and a larger surface area for catalyst interaction. These features collectively contribute to potentially improved electrochemical performance, making this technology a promising solution for enhancing the efficiency and effectiveness of catalyst supports in a variety of electrochemical applications.Potential ApplicationsFuel Cell Technology: The ability to efficiently conduct ions makes this technology particularly beneficial for fuel cells, where enhanced ion exchange can lead to better performance and energy efficiency.Battery Manufacturing: In advanced battery technologies, such as lithium-ion or solid-state batteries, the porous ionomer layer could improve ion transport between electrodes, potentially increasing battery life and charging speed.Water Purification Systems: Electrochemical processes are often used in water purification and desalination. This technology could enhance the efficiency of such systems by improving ion exchange and catalytic reactions.Electrolysis Systems: For hydrogen production through water electrolysis, the technology could improve the efficiency of hydrogen generation by providing a more effective catalyst support, thereby lowering energy consumption.Sensors and Diagnostics: In sensors that rely on electrochemical detection, the porous structure could facilitate faster and more sensitive detection of chemical or biological agents by improving the surface area for reactions.",
    "patents": "2023-137-01, US, 63/444,822 Provisional (Expired) 2023-137-02, US, 63/551,354 Provisional (Active)",
    "page_url": "https://cmu.flintbox.com/technologies/c7de80cb-9e37-4cb1-956a-fae8553a7a6c",
    "llm_summary": "**Summary:** This technology introduces a low-cost, scalable method for fabricating a hierarchically porous ionomer layer with an open pore-structure, enhancing its role as an ion-conducting catalyst support. It supports versatile catalyst coating methods (e.g., chemical vapor deposition, atomic layer deposition) and features pores ranging from 0.5\u20135 \u03bcm, enabling efficient catalyst deposition and improved electrochemical performance.  \n\n**Applications:** Key applications include fuel cell technology, battery manufacturing (e.g., lithium-ion or solid-state batteries), and water purification or desalination systems.  \n\n**Problem Solved:** The technology addresses the need for efficient ion conduction and catalyst support in electrochemical applications, improving performance, energy efficiency, and scalability.",
    "llm_teaser": "\"Revolutionize electrochemical performance with a low-cost, scalable hierarchically porous ionomer layer that enhances ion conduction, enables versatile catalyst deposition, and boosts efficiency across fuel cells, batteries, and water purification systems.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "A Method for Creating Self-Refining Games using Player Analytics",
    "ip_number": "14-151",
    "published_date": "Jun 9th, 2023",
    "ip_description": "This method uses sample player data to concentrate precomputation around the states that users are most likely to encounter, resulting in improved efficiency and responsiveness in the system. This method allows for self-refining games whose dynamics improve with play, ultimately providing realistically rendered, rich fluid dynamics in real time.The advantage of this analytics-driven training approach yields lower model error and fewer visual artifacts than a heuristic training strategy. Additionally, by analyzing sample player data and identifying the most likely states, precomputation efforts can be prioritized on data that will have the greatest impact on user experience or system functionality. This ensures that the system is optimized for the scenarios that matter the most to users, leading to a more tailored and personalized experience.Data-driven simulation demands good training data drawn from a vast space of possible simulations. While fully sampling these large spaces is infeasible, in practical applications, such as gameplay, users explore only a vanishingly small subset of the dynamical state space. By concentrating precomputation around these frequently encountered states, computational resources can be allocated more efficiently. Rather than precomputing and storing data for all possible states, which can be resource-intensive and time-consuming, focus will be on the states that have a higher probability of being encountered. This targeted precomputation approach reduces the computational burden and optimizes resource utilization.This method is a sampling approach that takes advantage of this observation by concentrating precomputation around the states that users are most likely to encounter. This technique is demonstrated in a prototype self-refining game whose dynamics improve with play, ultimately providing realistically rendered, rich fluid dynamics in real time on a mobile device. This analytics-driven training approach yields lower model error and fewer visual artifacts than a heuristic training strategy.In VR and AR applications, analyzing sample user data can help identify the most common interactions, environments, or objects that users are likely to encounter. This information can be utilized to precompute and optimize rendering, physics simulations, or audio processing, focusing computational resources on the elements that contribute most to the user's experience.Sample user data in e-commerce platforms can provide insights into popular products, frequently visited pages, or typical user navigation patterns. By concentrating precomputation around these likely user states, such as generating personalized recommendations or preloading relevant product information, the system can enhance browsing and shopping experiences, improving conversion rates and customer satisfaction.Social media platforms analyze user behavior and engagement patterns to optimize the content displayed in users' feeds. By leveraging sample user data, precomputation can be focused on the types of content, posts, or interactions that are most likely to resonate with each individual user. This helps create personalized and engaging feeds, improving user satisfaction and platform usage.Sample user data can be used in video streaming services to concentrate precomputation on the most frequently accessed videos, genres, or playback scenarios. By analyzing user viewing habits, the system can optimize video transcoding, buffering, or adaptive streaming algorithms, ensuring a seamless and high-quality viewing experience for popular content.In navigation systems and mapping applications, analyzing sample user data can provide insights into commonly visited locations, popular routes, or preferred points of interest. By concentrating precomputation around these likely user states, such as caching map data or optimizing route calculations, the system can improve responsiveness, reduce latency, and enhance the overall navigation experience.",
    "patents": "10,147,220",
    "page_url": "https://cmu.flintbox.com/technologies/b2340722-f8a6-4b08-887b-13a17692db33",
    "llm_summary": "**Summary:**  \nThis technology introduces a method for creating self-refining games by using player analytics to focus precomputation on the most frequently encountered game states. It improves efficiency, responsiveness, and realism in real-time rendering, particularly for fluid dynamics, while reducing model error and visual artifacts. The approach optimizes computational resources by prioritizing data that enhances user experience.\n\n**Applications:**  \n1. Gaming and interactive entertainment (e.g., self-refining games with real-time fluid dynamics).  \n2. Virtual Reality (VR) and Augmented Reality (AR) applications for optimized rendering and simulations.  \n3. E-commerce, social media, video streaming, and navigation systems for personalized and efficient user experiences.\n\n**Problem Solved:**  \nThe method addresses the inefficiency of precomputing and storing data for all possible states in large simulation spaces by focusing on the most likely user-encountered states, reducing computational burden and improving system performance.",
    "llm_teaser": "\"Revolutionize gaming and beyond with self-refining systems that use player analytics to focus computational resources on the most impactful states, delivering hyper-responsive, realistic experiences in real time while reducing errors and optimizing efficiency.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Acid Mine Drainage Remediation: Aluminum Chelation Using Functional Graphenic Materials",
    "ip_number": "2020-302",
    "published_date": "Jun 8th, 2023",
    "ip_description": "Our Functional Graphenic Materials (FGMs) may be applied in passive remediation of contaminated water. The technology includes at least six unique FGM scaffolds that incorporate a variety of metal-chelating groups, such as carboxylic acids, hydroxamic aciFGMs may also be applied directly to a water supply. Due to their insolubility, FGMs may be recovered along with the metals.Recent research supports FGMs having negligible impact on environmental microflora (e.g., experiments demonstrate minimal bactericidal effects on Escherichia coli, even at high concentrations).Acid mine drainage (AMD) is a pervasive source of metal pollution that severely impacts freshwater ecosystems and has a direct impact on human health. Conventional active and passive methods work very well for removing iron in AMD remediation, which is typically the highest metallic impurity. However, conventional passive remediation fails to remove all aluminum, which has severe ecological implications. Removal of aluminum ions using chelation, which traditionally uses small molecules that bind metals tightly for sequestration, holds promise. Yet, chelation strategies are limited because once introduced into surface water, small molecules are difficult to reclaim and often persist in the environment as pollutants.\n\nTo address limitations existing in previous chelation strategies, CMU researchers have designed six unique scaffolds based on functional graphenic materials (FGMs) to create non-soluble scaffolds that could be placed at the end of a passive remediation process as a polisher to remove persistent aluminum. When tested for efficacy, all six FGMs successfully demonstrated a reversible capacity to remove aluminum from acidic water, chelating up to 21 ug per mg FGM. Further, when exposed to E. coli as an approximation for environmental compatibility, viability was unaffected even at high concentrations, suggesting these FGMs to be non-toxic and a viable candidate for passive chelation-based remediation.Our\nFunctional Graphenic Materials (FGMs) can remove persistent metals such as\naluminum from acidic water (e.g., our research shows they are capable of chelating\nup to 21 \u03bcg of Al/mg of FGM). The FGMs are sustainable compared to existing\nmethods, as they are reversible after chelation and may be regenerated for reuse.\nAdditionally, when compared to current passive remediation methods, they are\nable to remove more aluminum and require less maintenance.1.\nAcid Mine Drainage Remediation2.\nMetal Recovery3.\nMedical Applications:\n\u00b7\nPotentially\nadaptable to reduce aluminum toxicity in dialysis patients.",
    "patents": "PCT/US2021/035901; 18/007,853",
    "page_url": "https://cmu.flintbox.com/technologies/23c8d981-524e-4da7-94cf-bc16abcece48",
    "llm_summary": "**Summary:** Functional Graphenic Materials (FGMs) are insoluble scaffolds designed for passive remediation of acid mine drainage (AMD), specifically targeting aluminum removal. They can chelate up to 21 \u03bcg of aluminum per mg of FGM, are reversible and reusable, and have minimal environmental impact, as demonstrated by non-toxicity to E. coli.  \n\n**Applications:**  \n1. Acid mine drainage remediation.  \n2. Metal recovery from contaminated water.  \n3. Potential medical applications, such as reducing aluminum toxicity in dialysis patients.  \n\n**Problem Solved:** FGMs address the limitations of conventional passive remediation methods, which fail to effectively remove persistent aluminum from AMD, a major source of metal pollution impacting ecosystems and human health.",
    "llm_teaser": "\"Revolutionize acid mine drainage cleanup with Functional Graphenic Materials (FGMs)\u2014non-toxic, reusable scaffolds that effectively remove persistent aluminum, outperforming traditional methods while safeguarding ecosystems and enabling sustainable metal recovery.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Polymer carriers for Temperature-activated or pH-activated delivery of agrochemicals in crop plants",
    "ip_number": "2020-340",
    "published_date": "Jun 8th, 2023",
    "ip_description": "Nano-carriers can be loaded with plant therapeutics, pesticides, or other compounds. Researchers have demonstrated that the nano-carriers not only exhibit increased foliar uptake, but may also translocate to different compartments of the plant.Nano-carriers may be adapted to release their cargo in response to changes in pH, which can be an indicator of disease in a plant.Nano-carriers may also be tailored to administer compounds in response to changes in temperature, which can assist in alleviating and managing heat stress in plants.Star polymers were developed with a poly(acrylic acid) (PAA) core and temperature-responsive poly(N-isopropyl acrylamide)  (PNIPAm) shell. The core is negatively charged and can be loaded with a significant amount (~0.5g/g) of positively charged molecules (e.g. antibiotics with amine functional groups). The polymers are readily taken up into plants upon foliar application, translocated to different parts of the plant. Upon heating the plants, in this case to 40 C, the drug is released into the plant vasculature. The temperature at which this delivery occurs can be controlled by changing the composition of the shell. The type of drug to be loaded can be changed by changing the core composition. The overall goal is to be able to load the material into the plants, then have the drug release only when the plants are under heat stress. The released drug will allow the plants to survive that peak heat stress. Right now there are no available methods for this purpose.Nano-carriers\nallow for less wasteful application of agrochemicals, from both an economic and\nenvironmental angle. Under existing agrochemical practices, around 90% of\napplied compounds wash off leaves when applied, leading to excess product use\nand environmental contamination. These nano-carriers provide a solution to this\nunsustainable practice. Increased uptake means that less compound needs to be\nused, and smaller amounts leech into the environment as pollution.1. Agricultural applications including industrial\nand other food-generating crops, and ornamental plants",
    "patents": "PCT/US2021/038449; 18/012,048",
    "page_url": "https://cmu.flintbox.com/technologies/67e90274-7e94-43e5-a9a2-f55ad49ec386",
    "llm_summary": "**Summary:** This technology involves nano-carriers made of star polymers with a poly(acrylic acid) core and a temperature-responsive poly(N-isopropyl acrylamide) shell. These carriers can be loaded with agrochemicals, such as pesticides or antibiotics, and release their cargo in response to pH changes (indicative of disease) or temperature changes (e.g., heat stress). They exhibit high foliar uptake, translocate within plants, and enable controlled, targeted delivery of compounds.  \n\n**Applications:**  \n1. Agricultural crops (industrial and food-generating).  \n2. Ornamental plants.  \n\n**Problem Solved:** Current agrochemical practices result in significant waste, with ~90% of applied compounds washing off leaves, leading to economic inefficiency and environmental pollution. This technology reduces waste by improving uptake and enabling targeted, condition-responsive delivery of agrochemicals.",
    "llm_teaser": "\"Revolutionize crop protection with smart polymer nano-carriers that deliver agrochemicals precisely when and where plants need them\u2014responding to heat stress or disease signals\u2014while drastically reducing waste and environmental impact.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Method to implant integrated circuit components in an all-elastomer \"robot skin\"",
    "ip_number": "2017-120",
    "published_date": "May 1st, 2023",
    "ip_description": "This invention builds on previously patented work developed by Alexi Charalambides while at University of Maryland. The previous work demonstrated a method to manufacture an all-elastomer \"robot skin\" capable of tactile sensing. The robot skin consisted of a clear silicone with patterned conductive silicone features. The latest novelty adds an additional step to this manufacturing process to embed integrated circuit components. A robot skin with embedded integrated circuit components could be used in soft wearable patches for wireless biomonitoring, which is of special interest to the military and medical communities.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/1c21c2da-f6c4-4c87-8036-03541e9f31e9",
    "llm_summary": "**Summary:**  \nThis invention enhances a previously patented method for creating an all-elastomer \"robot skin\" by embedding integrated circuit components into the skin. The robot skin, made of clear silicone with patterned conductive silicone features, now includes embedded electronics, enabling advanced functionalities like tactile sensing and wireless biomonitoring.\n\n**Applications:**  \n1. Soft wearable patches for wireless biomonitoring in medical applications.  \n2. Military applications for advanced sensing and monitoring.  \n3. Robotics for tactile sensing and enhanced interaction capabilities.  \n\n**Problem Solved:**  \nThe technology addresses the challenge of integrating electronic components into soft, flexible materials, enabling the creation of functional, all-elastomer robot skins for advanced sensing and monitoring applications.",
    "llm_teaser": "\"Revolutionize soft robotics and wearable tech with an all-elastomer 'robot skin' that embeds integrated circuits, enabling advanced wireless biomonitoring for military and medical applications.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "ClueWeb22 dataset",
    "ip_number": "2022-253",
    "published_date": "Mar 29th, 2023",
    "ip_description": "ClueWeb22 is the newest in the Lemur Project ClueWeb line of datasets that support research on information retrieval, natural language processing and related human language technologies.This new dataset was developed by the Lemur Project with significant assistance and support from Microsoft Corporation. ClueWeb22 is available for research purposes only.ClueWeb22 has several novel characteristics compared with earlier ClueWeb datasets. It is much larger (10 billion documents). Documents are of higher quality (selected from a commercial search engine index). Documents are available in several formats (HTML, clean text, screen shots). Document outlink and inlink data is provided in a convenient format. Document page analyses are provided that reveal where on a page text was displayed, and what was near it.The complete dataset fills 14 \u00d7 18 TB disks, which is expensive to distribute and store, thus it isdistributed in different subsets and formatsto support the most common uses. Some subsets may be downloaded for free. Others are distributed on disk and require payment.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/03594d0d-c65c-4906-a858-02a7ad7ea727",
    "llm_summary": "**Summary:** ClueWeb22 is a large-scale dataset with 10 billion high-quality documents, available in multiple formats (HTML, clean text, screenshots), and includes document outlink/inlink data and page analyses. It is designed for research in information retrieval and natural language processing, distributed in subsets to balance accessibility and storage costs.  \n\n**Applications:** Research in information retrieval, natural language processing, and human language technologies.  \n\n**Problem Solved:** Provides a comprehensive, high-quality dataset to support advanced research in language technologies, addressing the need for large-scale, diverse, and well-structured data for academic and industrial research.",
    "llm_teaser": "\"Unlock groundbreaking advancements in information retrieval and NLP with ClueWeb22, a massive, high-quality dataset of 10 billion documents, offering unprecedented features like HTML, clean text, screenshots, and detailed page analyses\u2014available in flexible formats to fuel cutting-edge research.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "End-to-End Platform for Generating SOAP Notes from Doctor-Patient Conversations",
    "ip_number": "2021-002",
    "published_date": "Feb 16th, 2023",
    "ip_description": "This technology describes robust pipelines that leverage deep summarization models to generate these notes based on transcripts of conversations between doctors and patients.*\nModular summarization methods can extract relevant information from clinical summarizations in a structured and efficient manner, reducing the time and effort required to generate SOAP notes\nThis technology addresses difficult challenges in NLP summarization, leading to improved accuracy and completeness of the generated SOAP notes.\nFollowing each patient visit, physicians draft long semi-structured clinical summaries called SOAP notes and contained in an Electronic Health Records (EHR) . While the SOAP (Subjective, Objective, Assessment, and Plan) notes are undoubtedly invaluable to clinicians and researchers, creating digital SOAP notes is burdensome and time consuming. This technology describes complete pipelines to leverage deep summarization models for generating whole SOAP notes based on clinical conversations, and these models were quantitatively evaluated.\nModular summarization methods will improve the consistency and standardization of SOAP notes, leading to more accurate and reliable documentation and enabling better continuity of care.\nEMR/EHR; Telehealth",
    "patents": "17/736,624",
    "page_url": "https://cmu.flintbox.com/technologies/e5d37a73-8c43-4439-80a9-3474144a1ec4",
    "llm_summary": "**Summary:** This technology provides an end-to-end platform that uses deep summarization models to automatically generate SOAP (Subjective, Objective, Assessment, and Plan) notes from doctor-patient conversation transcripts. It employs modular summarization methods to extract and structure relevant clinical information efficiently, improving accuracy and reducing the time required for documentation.  \n\n**Applications:** This technology is applicable in Electronic Medical Records (EMR)/Electronic Health Records (EHR) systems and telehealth platforms, streamlining clinical documentation for healthcare providers.  \n\n**Problem Solved:** It addresses the time-consuming and burdensome process of manually creating SOAP notes, improving the accuracy, consistency, and standardization of clinical documentation.",
    "llm_teaser": "\"Revolutionize clinical documentation with an AI-powered platform that automatically generates accurate, structured SOAP notes from doctor-patient conversations, saving time and improving care continuity.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "catlas",
    "ip_number": "2022-242",
    "published_date": "Jan 24th, 2023",
    "ip_description": "catlas is open source software that is used to systematically enumerate surfaces and adsorption sites for catalyst materials, using open source machine learning potentials to predict their properties. It implements strategies that are standard and established in the catalysis community. It also implements parallel distribution strategies using the open source dask software to make enumeration and prediction faster.\n\nThe code is available under an MIT license at https://github.com/ulissigroup/catlas",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/c083bf6e-265c-42c0-8119-cce7751eee29",
    "llm_summary": "**Summary:** catlas is open source software designed to systematically enumerate surfaces and adsorption sites for catalyst materials. It uses open source machine learning potentials to predict material properties and implements parallel distribution strategies with dask for faster computation.  \n\n**Applications:** Catalysis research, materials science, and chemical engineering.  \n\n**Problem Solved:** catlas addresses the challenge of efficiently enumerating and predicting properties of catalyst surfaces, which is critical for accelerating catalyst design and optimization.",
    "llm_teaser": "\"Unlock the full potential of catalyst materials with **catlas**, an open-source tool that accelerates the discovery of optimal surfaces and adsorption sites using machine learning and parallel computing, all under an MIT license.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Actitouch: Robust Touch Detection for On-Skin AR/VR Interfaces",
    "ip_number": "2018-258",
    "published_date": "Aug 23rd, 2022",
    "ip_description": "ActiTouch leverages the conductivity of the human body, which conveniently serves as a transmission medium for RF signals.This method use skin as a convenient surface tactile for users to conduct touch-driven interactions.High accuracy: 93.8% on average, as observed in the user studyActiTouch enables precise, low-latency touch segmentation by using the body as an RF waveguide. Users need only wear one wristband emitter (e.g., smartwatchs) and a head-worn receiver (e.g., AR/VR headsets). When a user touches the other arm, a circuit path is formed, which also increases airborne RF radiation. This path can be used as a touch detection mechanism.This system requires no cumbersome instrumentation of the fingers or hands, requiring only a single wristband (e.g., smartwatch) and sensors integrated into an AR/VR headset. Combined with computer vision, this method enables a system with both high tracking precision and robust touch detection.AR/VR games and other applications",
    "patents": "17/069,782",
    "page_url": "https://cmu.flintbox.com/technologies/bcf35a2d-731e-44ee-b2b9-832ddc9c63d9",
    "llm_summary": "**Summary:** ActiTouch is a touch detection system that uses the human body as an RF waveguide for precise, low-latency touch segmentation. It requires only a wristband emitter (e.g., smartwatch) and a head-worn receiver (e.g., AR/VR headset), achieving 93.8% accuracy in user studies. The system detects touch by forming a circuit path when the user touches their arm, eliminating the need for finger or hand instrumentation.  \n\n**Applications:** AR/VR gaming, on-skin interfaces for AR/VR systems, and interactive applications requiring robust touch detection.  \n\n**Problem Solved:** ActiTouch addresses the challenge of cumbersome and less accurate touch detection methods in AR/VR interfaces by leveraging the body's conductivity for seamless, high-precision interactions.",
    "llm_teaser": "\"ActiTouch revolutionizes AR/VR interaction by turning your skin into a touch-sensitive interface, delivering 93.8% accuracy with just a wristband and headset\u2014no extra gadgets needed.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Magnetic Elastomer for Deformation Sensing",
    "ip_number": "2019-030",
    "published_date": "Jun 10th, 2022",
    "ip_description": "We are introducing a new polymer substrate with magnetic properties. Small magnetic particles embedded inside an elastomer create a unique surrounding magnetic field. When the elastomer substrate is deformed, the magnetic particles change position and modify the surrounding magnetic field accordingly. Coupled with a magnetic sensor, we can measure and track these small changes in magnetic field and infer the applied deformation. Our goal is to develop a soft, continuous tactile sensor to localize and quantify applied deformations. The sensor's stretchable, soft  and waterproof properties lends itself to applications in wearables or physiological monitoring. In particular, in conjunction with large-scale data collection and statistical analysis, this simple sensor could be tremendously helpful in robotic manipulation tasks.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/1d0ad66d-95f7-4a56-b98e-393d4bc96cfb",
    "llm_summary": "**Summary:**  \nThis technology introduces a magnetic elastomer substrate embedded with magnetic particles, enabling deformation sensing through changes in the surrounding magnetic field. Coupled with a magnetic sensor, it can localize and quantify deformations, offering a soft, stretchable, and waterproof solution ideal for tactile sensing applications.\n\n**Applications:**  \n1. Wearable technology for physiological monitoring.  \n2. Robotic manipulation tasks requiring precise deformation tracking.  \n3. Large-scale data collection and analysis in soft robotics.  \n\n**Problem Solved:**  \nThe technology addresses the need for soft, continuous tactile sensors capable of accurately localizing and quantifying deformations in applications like wearables and robotics.",
    "llm_teaser": "\"Revolutionize tactile sensing with our magnetic elastomer technology\u2014a soft, stretchable, and waterproof sensor that precisely tracks deformations, enabling breakthroughs in wearables, robotics, and physiological monitoring.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "WALT: Watch and Learn Time-lapse dataset",
    "ip_number": "2022-204",
    "published_date": "Jun 10th, 2022",
    "ip_description": "The intellectual property being disclosed includes images captured from cameras, rendered images, and source code. The captured images are from 12 cameras from 2 sources. One source of data are cameras that we deployed on CMU's campus. The other source of data were from varying locations acquired through live, public YouTube video feeds. Rendered images were synthetically generated using computer graphics methods to emulate captured images of a parking lot. Source code includes code for recording images from YouTube.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/7204c72f-51bb-4b11-97cf-229f00f83d0e",
    "llm_summary": "**Summary:** The WALT: Watch and Learn Time-lapse dataset includes images from 12 cameras (deployed on CMU's campus and sourced from live YouTube feeds), synthetically rendered images of parking lots, and source code for recording images from YouTube. It combines real-world and computer-generated data for diverse applications.\n\n**Applications:** Surveillance and monitoring, computer vision research, and synthetic data generation for machine learning training.\n\n**Problem Solved:** The technology addresses the need for diverse, high-quality datasets combining real-world and synthetic imagery to improve computer vision and machine learning models.",
    "llm_teaser": "\"WALT: Watch and Learn Time-lapse dataset revolutionizes AI training with a unique blend of real-world campus camera footage, live YouTube feeds, and synthetic parking lot imagery, offering unparalleled diversity and scalability for computer vision applications.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Method and Software for Prediction of Protein pKa (Protonation States) with Machine Learning",
    "ip_number": "2022-172",
    "published_date": "Jun 10th, 2022",
    "ip_description": "The behavior of proteins is closely related to the protonation states of the residues. Therefore, prediction and measurement of pKa are essential to understand the basic functions of proteins. In this work, we develop a new empirical scheme for protein pKa prediction that is based on deep representation learning. It combines machine learning with atomic environment vector (AEV) and learned quantum mechanical representation from ANI-2x neural network potential (J. Chem. Theory Comput. 2020, 16, 4192). The scheme requires only the coordinate information of a protein as the input and separately estimates the pKa for all five titratable amino acid types. Obtained results were compared with the widely used empirical approach PROPKA. The new empirical model provides accuracy with MAEs below 0.5 for all amino acid types. It surpasses the accuracy of PROPKA and performs significantly better than methods used in current practice.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/a678f257-2b4a-4425-a8cd-d63ab33d34df",
    "llm_summary": "**Summary:** This technology introduces a novel method and software for predicting protein pKa (protonation states) using machine learning. It leverages deep representation learning, combining atomic environment vectors (AEV) and quantum mechanical representations from the ANI-2x neural network potential. The model requires only protein coordinate data as input and achieves high accuracy, with mean absolute errors (MAEs) below 0.5 for all five titratable amino acid types, outperforming the widely used PROPKA method.\n\n**Applications:** This technology is applicable in drug discovery, protein engineering, and structural biology, where understanding protein behavior and protonation states is critical for designing effective therapeutics and studying protein functions.\n\n**Problem Solved:** The technology addresses the challenge of accurately predicting protein pKa values, which are essential for understanding protein behavior and function, by providing a more accurate and efficient alternative to existing empirical methods like PROPKA.",
    "llm_teaser": "\"Revolutionize protein analysis with our machine learning-driven pKa prediction tool, leveraging deep representation learning and quantum mechanical insights to deliver unmatched accuracy\u2014outperforming PROPKA with MAEs below 0.5 for all titratable amino acids, using only protein coordinates as input.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Virtual Meeting Media Controller",
    "ip_number": "2021-065",
    "published_date": "Apr 26th, 2022",
    "ip_description": "The Virtual Meeting Media Controller allows users to quickly and intuitively control video conferencing and virtual meeting applications. With easily accessible buttons, it eliminates mouse and keyboard fumbling.The media controller is compatible with a variety of virtual meeting programs (e.g., Zoom\u00ae, Skype\u00ae, Teams\u00ae, BlueJeans\u00ae, Webex\u00ae). The controller can detect programs upon launch, conveniently retrieving preset button assignments for out-of-the-box funcMappable and customizable buttons are available for power users who require even more control and functionality.While experiencing recent global pandemic, diverse format of\nmedia for communication emerges and stand at the center of our daily lives.\nRemote meeting is beyond the subsidiary or complementary way to communicate and\nvarious software for support class, project, and works are prevalent these\ndays. However, this variety requires us to get used to many different computing\ntechnologies in short time and occurs the accessibility issue of the technology\nin different ages and situations. For example, K-12 students undergo the\ndistraction issue of remote class by controlling interface of on-line meeting\nsystems, instructors meet the frequent technical issue while presenting and\ntransiting materials on online. To improve this difficult for post-pandemic,\nthe invented device, External Media Controller, provides users intuitive\ncontrols of computing interface with remote class, meeting, and even design. Using\nthe device, users can focus on the communication through computing interface\nwith the physical buttons for specific functions which users can customize.\nThis intuitive controls over the various computing interface catalyze the\ncommunication more immersive, avoiding distraction from moving and hovering\nmouse pointers to find many functions in the interface.The Virtual\nMeeting Media Controller greatly reduces the amount of attention diverted from\nthe task at hand, allowing users to focus on interacting with their audiences\nor managing their conferences. Virtual conferencing/meeting software is playing\nan ever-increasing role in our professional and personal lives, so there is a\nneed to make operating such software as intuitive, efficient, and seamless as\npossible.1. Workplace\n2. Entertainment:\nStreamers (e.g., gamers and other internet content creators) can use the media controller to facilitate interaction with their fans and operate various streaming platform functions.\n3. Education:\nEducators can use the media controller to easily switch between tasks (e.g., controlling multimedia displays and monitoring student participation).",
    "patents": "17/683,516",
    "page_url": "https://cmu.flintbox.com/technologies/d84dd897-ffaf-42c8-93e9-36be8839957a",
    "llm_summary": "**Summary:**  \nThe Virtual Meeting Media Controller is a device that provides intuitive, button-based control for video conferencing and virtual meeting applications, eliminating the need for mouse and keyboard use. It is compatible with popular platforms like Zoom, Skype, Teams, BlueJeans, and Webex, and offers customizable buttons for advanced functionality. The device enhances user focus by simplifying interface navigation and reducing distractions during virtual meetings, classes, or streaming.\n\n**Applications:**  \n1. **Workplace:** Facilitates seamless control of virtual meetings and conferences.  \n2. **Entertainment:** Helps streamers manage interactions and platform functions during live broadcasts.  \n3. **Education:** Assists educators in switching tasks, controlling multimedia, and monitoring student participation during remote classes.  \n\n**Problem Solved:**  \nThe technology addresses the challenges of navigating complex virtual meeting interfaces, reducing distractions, and improving accessibility for users of all ages and technical skill levels, particularly in remote work, education, and streaming environments.",
    "llm_teaser": "\"Take control of your virtual meetings with the Virtual Meeting Media Controller\u2014an intuitive, customizable device that eliminates mouse and keyboard fumbling, letting you focus on seamless communication across Zoom, Teams, and more.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Food-Derived Chemicals for Modulating Permeability of Biological Barriers",
    "ip_number": "2018-188",
    "published_date": "Sep 15th, 2020",
    "ip_description": "Naturally occurring permeation enhancer\nDelivery of macro-molecular drugs\nPelargonidin: a strawberry-derived intestinal permeation enhancer for oral delivery of macromolecule drugs.\nOral delivery of biologic drugs would revolutionize modern medicine, due to its ease of use, high patient compliance, and physiological advantages when compared with injections. However, successful oral formulations must overcome poor transport of large therapeutic molecules from the intestines to the bloodstream. Chemical permeation enhancers of the intestinal epithelial barrier have been identified, and some have entered clinical trials, but their translation has traditionally been hampered by cytotoxicity. This ongoing need inspired us to investigate food components as known non-toxic chemicals in the intestines, and their potential application as intestinal permeation enhancers. As a result, we have demonstrated that the strawberry pigment pelargonidin and some of its molecular relatives are effective, nontoxic enablers of oral biologic absorption (Figure 1).\n\tPelargonidin and its molecular family, the anthocyanidins, are aglycone (sugar-free) versions of the anthocyanin pigments commonly found in wines, fruits, vegetables, and many flowers. The general structure (Figure 2a) comprises the three-ring flavylium cation with substitutions of \u2013OH or \u2013OCH3 groups at different combinations of the denoted \"R\" sites. In an intestinal cell culture screen of six anthocyanidins, three members of this family increased drug permeability across tissue, with pelargonidin (Plrgn) performing particularly well (Figure 2b). These findings underscore the importance of this particular molecular structure, and the potential for application of additional, effective compounds within the anthocyanidin family.\nWe have further demonstrated that pelargonidin can be used to enable oral delivery of insulin, a 5.8 kDa protein, in mice (Figure 3a). Impressively, the oral combination of pelargonidin and a one unit per kilogram insulin dose provided a sustained decrease in blood sugar, amounting to 140% of the total drug activity when compared to the current gold standard of subcutaneous injection. Additionally, we showed that pelargonidin improves uptake of the linear polymers 40 kDa and 70 kDa dextran (Figure 3b). This implies that this system can be applied to bioactive polymers (including heparin) and nucleic acids (including siRNA). To this end, because the permeation enhancer strategy of oral macromolecule delivery is not dependent on the drug chemistry, anthocyanidins have the potential to orally deliver a broad range of current biologic drug candidates without further chemical development.\nOral delivery of large molecules.",
    "patents": "PCT/US2019/027866",
    "page_url": "https://cmu.flintbox.com/technologies/bc8c5b45-4a9a-4c3e-bf17-81ea942f0445",
    "llm_summary": "**Summary:**  \nThis technology involves the use of pelargonidin, a strawberry-derived anthocyanidin, as a non-toxic intestinal permeation enhancer for oral delivery of macromolecular drugs. It has demonstrated effectiveness in improving the absorption of insulin and other large molecules, such as dextran, in preclinical studies, offering a potential alternative to injectable drug delivery.\n\n**Applications:**  \n1. Oral delivery of biologic drugs, including insulin and other macromolecular therapeutics.  \n2. Enhancing absorption of bioactive polymers (e.g., heparin) and nucleic acids (e.g., siRNA) for therapeutic use.  \n3. Development of non-toxic, food-derived permeation enhancers for pharmaceutical formulations.  \n\n**Problem Solved:**  \nThis technology addresses the challenge of poor intestinal absorption of large therapeutic molecules, enabling effective oral delivery of biologic drugs and reducing reliance on invasive injection methods.",
    "llm_teaser": "\"Revolutionize oral drug delivery with pelargonidin, a strawberry-derived, non-toxic permeation enhancer that enables effective absorption of macromolecular drugs like insulin, offering a safer, more patient-friendly alternative to injections.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "inventory_manager",
    "ip_number": "2020-120",
    "published_date": "Jul 1st, 2020",
    "ip_description": "inventory_manager provides a plug-in based way of systems integration of internet protocal (ip) based assets following the philosophy of modern configuration management tools such as Puppet or Ansible. This creation could be used for integrating ip based assets across systems management tools. The advantage is reduced time to integrating ip-based assets across management platforms and the ability to rapidly change the requirements of desired states based on regular expressions and a priority based process of applying states.\n\nThe software is available under an MIT license here: https://github.com/dmatthewsbnd251/Inventory_Manager",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/23bfcd88-125b-429a-ab20-5c72e0c59e09",
    "llm_summary": "**Summary:**  \ninventory_manager is a plug-in-based tool for integrating IP-based assets across systems management platforms, inspired by modern configuration management tools like Puppet or Ansible. It enables rapid integration of IP-based assets and allows for dynamic changes to desired states using regular expressions and priority-based state application.\n\n**Applications:**  \n1. Systems integration for IT infrastructure management.  \n2. Automation of IP-based asset configuration across multiple platforms.  \n3. Streamlining operations in industries reliant on networked devices, such as telecommunications or data centers.\n\n**Problem Solved:**  \nThe tool reduces the time and complexity of integrating IP-based assets across different management platforms, enabling faster and more flexible configuration changes.",
    "llm_teaser": "\"Revolutionize IP-based asset integration with *inventory_manager*\u2014a plug-in driven tool that slashes setup time and enables dynamic, priority-based state management across systems, all powered by modern configuration principles like Puppet and Ansible.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "GymCam: Using a Camera to Detect, Recognize, and Track Multiple Repetitive Exercises Simultaneously",
    "ip_number": "2019-063",
    "published_date": "Jun 2nd, 2020",
    "ip_description": "GymCam is a system for automatically detecting, recognizing and tracking multiple exercises simultaneously via a camera placed in the environment without any user intervention. All concurrently occurring exercises from other activities in the video are segmented, the type of each exercise is recognized, and the number of repetitions for each of them is counted. GymCam advances the field of real-time exercise tracking by filling some crucial gaps, such as tracking whole body motion, handling occlusion, and enabling single-point sensing for a multitude of users.1. Automatically detecting, recognizing and tracking multiple exercises simultaneously via a camera placed in the environment without any user intervention.2. Tracking whole body motion, handling occlusion, and enabling single-point sensing for a multitude of users.ExerciseSingle-point sensingHealth sensingComputer vision",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/61873d57-4cf4-4feb-9ccb-14594a2fad41",
    "llm_summary": "**Summary:** GymCam is a camera-based system that automatically detects, recognizes, and tracks multiple exercises simultaneously without user intervention. It segments concurrent exercises, identifies their types, and counts repetitions, while addressing challenges like whole-body motion tracking, occlusion handling, and single-point sensing for multiple users.  \n\n**Applications:**  \n1. Fitness and gym environments for automated exercise tracking.  \n2. Health monitoring and wellness programs.  \n3. Computer vision applications in multi-user activity recognition.  \n\n**Problem Solved:** GymCam addresses the challenge of real-time, automated tracking of multiple exercises in a shared space, overcoming issues like occlusion and the need for wearable devices or user input.",
    "llm_teaser": "\"GymCam revolutionizes fitness tracking by using a single camera to automatically detect, recognize, and count repetitions for multiple users performing different exercises simultaneously\u2014no wearables or user input required.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Sequence Generation using Recurrent Neural Networks with Continuous Outputs",
    "ip_number": "2018-242",
    "published_date": "May 11th, 2020",
    "ip_description": "Rare words are extremely common in any language. Yet, natural language processing tools that use deep learning methods to generate words---including machine translation, summarization, dialogue and personal assistants, question answering, speech recognition, speech translation, and others---generate words by sampling from a pre-defined, closed output vocabulary. This is done by computing scores for each candidate word and normalizing them to probabilities using a \"softmax\" layer. Since softmax is computationally expensive, current systems limit their output vocabulary to a few tens of thousands of most frequent words, sacrificing linguistic diversity by replacing the long tail of (millions) rare words by the \"unknown\" word token. Unsurprisingly, at test time this leads to an inferior performance when generating rare or out-of-vocabulary words. Despite the reduced output vocabulary, softmax is computationally the slowest layer. Moreover, its computation follows a large matrix multiplication to compute scores over the candidate words; this makes softmax expensive in terms of memory requirements and the number of parameters to learn.\n\nWe developed a new technique to generate low-dimensional continuous word representations, or \"word embeddings\" instead of the softmax layer. We train sequence-to-sequence models with continuous outputs by minimizing the distance between the output vector and the pre-trained word embedding of the reference word. At inference time, the model generates a vector and then searches for its nearest neighbor in the target embedding space to generate the corresponding word. This general architecture can in principle be used for any language generation task that uses sequence-to-sequence recurrent neural networks. To the best of our knowledge, this is the first work that uses word embeddings---rather than the softmax layer---as outputs in language generation tasks. While this idea is simple and intuitive, in practice, it does not yield competitive performance with standard training approaches that use cosine or Euclidean distance. A major innovation in our work is a novel probabilistic distance function to train the proposed model. We experimented with neural machine translation. In translation of two language pairs, into two languages, our translation systems perform on par with the state-of-the-art systems in terms of translation quality, while attaining up to 2.5x speed-up in training times, and 98% reduction in memory requirements for the output layer. These models are also capable of handling very large vocabularies without compromising on translation quality. The proposed architecture and the novel probabilistic loss have the potential to benefit broadly applications which have sequences as outputs. Our new loss function could be used as an objective function for problems which currently use cosine or Euclidean distance, such as learning word embeddings. Since the outputs of our models are continuous (rather than class-based), these models can greatly simplify training of generative adversarial networks for sequences.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/93260ca4-6e9e-44cb-a2ad-7cf47c0cc987",
    "llm_summary": "**Summary:** This technology introduces a novel approach to sequence generation using recurrent neural networks (RNNs) with continuous outputs, replacing the traditional softmax layer with low-dimensional continuous word embeddings. It achieves competitive performance in neural machine translation, offering up to 2.5x faster training times, 98% reduced memory requirements, and the ability to handle large vocabularies without compromising quality. A key innovation is a probabilistic distance function for training, which improves performance over standard distance metrics.\n\n**Applications:** This technology is applicable to natural language processing tasks such as machine translation, summarization, dialogue systems, question answering, speech recognition, and speech translation. It can also benefit generative adversarial networks (GANs) for sequence generation.\n\n**Problem Solved:** The technology addresses the limitations of softmax-based systems, which are computationally expensive, memory-intensive, and constrained by small output vocabularies, leading to poor performance with rare or out-of-vocabulary words.",
    "llm_teaser": "\"Revolutionize sequence generation with our novel recurrent neural network architecture that replaces softmax with continuous word embeddings, delivering state-of-the-art performance, 2.5x faster training, 98% reduced memory usage, and seamless handling of rare words\u2014unlocking linguistic diversity and scalability for NLP tasks.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "FitByte: Robust Diet Monitoring Using Sensor-Equipped Eyeglasses",
    "ip_number": "2019-064",
    "published_date": "Mar 17th, 2020",
    "ip_description": null,
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/19cbc3fa-21c7-474b-90dc-81f859ebca4d",
    "llm_summary": "**Summary:**  \nFitByte is likely a technology designed to monitor dietary habits using sensor-equipped eyeglasses. The system probably tracks food consumption, nutritional intake, or eating patterns in real-time, providing users with insights into their diet. The use of eyeglasses suggests a hands-free, wearable approach to diet monitoring.\n\n**Applications:**  \n1. Assisting individuals in managing dietary goals, such as weight loss or nutritional balance, by providing real-time feedback on food intake.  \n2. Supporting healthcare professionals in monitoring patients' eating habits for conditions like diabetes or obesity.\n\n**Problem Solved:**  \nFitByte addresses the challenge of accurately and conveniently tracking dietary intake without requiring manual input or additional devices.",
    "llm_teaser": "\"FitByte leverages sensor-equipped eyeglasses to provide precise and reliable diet monitoring, seamlessly integrating health tracking into everyday life.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "K-NRM: A Kernel-Based Neural Ranking Model For Full-Text Search Engines",
    "ip_number": "2018-065",
    "published_date": "Jan 16th, 2020",
    "ip_description": "K-NRM is a kernel based neural model for document ranking. Given a query and a set of documents, K-NRM uses a translation matrix that models word-level similarities via word embeddings, a new kernel-pooling technique that uses kernels to extract Multi-level soft match features, and a learning-to-rank layer that combines those features into the final ranking score. The whole model is trained end-to-end. The ranking layer learns desired feature patterns from the pairwise ranking loss. The kernels transfer the feature patterns into soft-match targets at each similarity level and enforce them on the translation matrix.\nThe word embeddings are tuned accordingly so that they can produce the desired soft matches.\nhttps://github.com/AdeDZY/K-NRM",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/8e0c5356-901a-4b0c-975e-e8f538d87b9a",
    "llm_summary": "**Summary:** K-NRM is a kernel-based neural ranking model designed for full-text search engines. It uses word embeddings, a translation matrix, and kernel-pooling to extract multi-level soft match features, which are combined into a final ranking score through a learning-to-rank layer. The model is trained end-to-end to optimize document ranking based on pairwise ranking loss.\n\n**Applications:** Full-text search engines, information retrieval systems, and document ranking platforms.\n\n**Problem Solved:** K-NRM addresses the challenge of accurately ranking documents in response to user queries by modeling word-level similarities and extracting multi-level soft match features, improving the relevance of search results.",
    "llm_teaser": "\"K-NRM revolutionizes full-text search by leveraging kernel-based neural ranking to model multi-level word similarities, enabling precise, end-to-end learning of soft-match patterns for superior document ranking.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "End-to-end Multi-modal Speech Recognition",
    "ip_number": "2018-180",
    "published_date": "Jan 16th, 2020",
    "ip_description": "Captioning (sub-titling) of video content is one of the hardest challenges for automatic speech processing, because input is generally very noisy. On the other hand, the availability of related visual information creates the opportunity of creating a multi-modal transcription of input speech, that could even be trained in an end-to-end fashion: if we \"see\" a car, it is much more likely that a video's commentary is on cars, than on cooking - Humans adapt to that without much effort, but deep neural network based automatic speech recognition (ASA) has so far not been able to fuse these information channels  effectively. All-neural end-to-end (E2E) approaches are a natural fit to this problem, and offer an elegant solution to this problem. We implemented two initial sequence-to-sequence and CTC based\nE2E ASA system on a sub-set of the \"how-to\" video data, and demonstrate improved token error rate using end-to-end training and are working to extend our work towards the full 2000h  Variants of that approach, which we are currently exploring, provide alternative ways of fusing the two modalities (speech and images/ videos) and expand our work towards summarization rather than transcription. Importantly, the implementation as a single model that is trained end-to-end on acoustic and video input improves performance on top of previous implementations, and demonstrated to overall viability of the approach.Captioning (sub-titling) of video content is one of the hardest challenges for automatic speech processing, because input is generally very noisy. This implementation as a single model that is trained end-to-end on acoustic and video input improves performance on top of previous implementations, and demonstrated to overall viability of the approach.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/0c51ea58-2240-48aa-8f80-111bbf8a82fb",
    "llm_summary": "**Summary:**  \nThis technology presents an end-to-end multi-modal speech recognition system that combines acoustic and visual inputs to improve transcription accuracy in noisy environments. It uses sequence-to-sequence and CTC-based models, demonstrating improved token error rates on \"how-to\" video datasets. The approach explores fusing speech and video modalities for tasks like summarization and transcription.\n\n**Applications:**  \n1. Video captioning and subtitling for media and entertainment.  \n2. Enhanced transcription for educational and instructional videos.  \n3. Multi-modal summarization for content creation and accessibility.\n\n**Problem Solved:**  \nThe technology addresses the challenge of accurately transcribing noisy video content by leveraging visual context to improve speech recognition, overcoming limitations of traditional single-modality approaches.",
    "llm_teaser": "\"Revolutionize video captioning with end-to-end multi-modal speech recognition, fusing audio and visual cues in a single neural model to deliver unprecedented accuracy in noisy environments.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Event Labeling through Analytic Media Processing",
    "ip_number": "2016-016",
    "published_date": "Jan 16th, 2020",
    "ip_description": "Building on state-of-the-art audio and video processing, along with general language analysis techniques, E-LAMP is an interactive system for multimedia event detection.\nThe invention describes a prototype capable of (1) analyzing massive numbers of digital multimedia files for the presence or absence of specific events, which are (2) stored in a representation that lends itself to efficient processing, supported by (3) an interface suitable for domain specialists, using \"event kits\". Due to the large amounts of data to be searched, the original data is processed only once, and is stored in an efficient index structure, which includes semantic information, and general knowledge stored in shallow ontology stubs. The system extends on the state-of-the-art in audio processing (speech-to-text, acoustic scene analysis, meta-data extraction), video processing (video concept and activity analysis, optical character recognition), and general language analysis techniques. From the information extracted from the original video data, the system creates an indexing representation, which is semantically rich enough to support event kits (text queries which are optionally supported by multimedia examples) for multimedia events. The semantic representation is high-level, in that items are represented as meaningful concepts, so that queries about multimedia events can be answered quickly and with high recall, yet it is also detailed, guaranteeing precision and allowing generation of feedback in a probabilistic framework.\n\nBuilding on state-of-the-art audio and video processing, along with general language analysis techniques, E-LAMP is an interactive system for multimedia event detection. The\ninvention describes a prototype capable of (1) analyzing massive\nnumbers of digital multimedia files for the presence or absence of\nspecific events, which are (2) stored in a representation that lends\nitself to efficient processing, supported by (3) an interface suitable\nfor domain specialists, using \"event kits\".",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/dec338a7-7729-4ad2-aa40-18d037bf98c9",
    "llm_summary": "**Summary:**  \nE-LAMP is an interactive system for multimedia event detection that leverages advanced audio, video, and language analysis techniques. It processes large volumes of digital multimedia files, stores them in an efficient index structure with semantic information, and provides a user-friendly interface for domain specialists using \"event kits\" to query and detect specific events.\n\n**Applications:**  \n1. Media and entertainment industry for content analysis and tagging.  \n2. Security and surveillance for event detection in video feeds.  \n3. Research and academia for multimedia data mining and analysis.  \n\n**Problem Solved:**  \nE-LAMP addresses the challenge of efficiently analyzing and retrieving specific events from massive amounts of multimedia data by creating a semantically rich, high-level indexing representation that ensures quick and precise query responses.",
    "llm_teaser": "\"E-LAMP revolutionizes multimedia event detection by combining advanced audio, video, and language analysis to create a semantically rich, efficient indexing system, enabling domain specialists to quickly and accurately search massive datasets with high recall and precision using intuitive 'event kits'.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Referee --- A system for compressing read alignment files",
    "ip_number": "2017-053",
    "published_date": "Jan 16th, 2020",
    "ip_description": "A computational method for compressing read alignment files.\nSee paper.https://github.com/Kingsford-Group/referee\nA computational method for compressing read alignment files.\nSee paper.https://github.com/Kingsford-Group/referee",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/6df736e6-543e-403f-8178-0c9eed987e2a",
    "llm_summary": "**Summary:** Referee is a computational method designed to compress read alignment files, which are commonly used in bioinformatics. It provides an efficient solution for reducing the storage size of these files while maintaining data integrity. The method is detailed in a paper and the code is available on GitHub.\n\n**Applications:** This technology is primarily useful in bioinformatics research, genomic data analysis, and large-scale sequencing projects where efficient storage and management of read alignment files are critical.\n\n**Problem Solved:** Referee addresses the challenge of managing large read alignment files, which can consume significant storage space and slow down data processing and sharing in genomic studies.",
    "llm_teaser": "\"Referee revolutionizes genomic data storage by compressing read alignment files with unprecedented efficiency, slashing storage needs while preserving critical data integrity\u2014unlocking faster, cost-effective genomic analysis.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Salmon: computational method for RNA-seq quantification.",
    "ip_number": "2017-057",
    "published_date": "Jan 16th, 2020",
    "ip_description": "An improved computational method estimating RNA-seq data. Source code was released under a GPL v3 license at https://github.com/COMBINE-lab/salmon",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/127c49f9-2c52-4882-966d-683ca6429c49",
    "llm_summary": "**Summary:** Salmon is a computational method designed for accurate and efficient quantification of RNA-seq data. It provides improved estimation of transcript abundance and is available as open-source software under the GPL v3 license, hosted on GitHub.  \n\n**Applications:** RNA-seq data analysis in genomics research, transcriptomics studies, and bioinformatics tool development.  \n\n**Problem Solved:** Salmon addresses the challenge of accurately estimating transcript abundance from RNA-seq data, enabling more reliable analysis of gene expression.",
    "llm_teaser": "\"Salmon revolutionizes RNA-seq quantification with its lightning-fast, highly accurate computational method, now freely available under GPL v3 for seamless integration into your bioinformatics pipeline.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "ROS module for Tobii Pro Glasses",
    "ip_number": "2018-040",
    "published_date": "Jan 16th, 2020",
    "ip_description": "ROS module for Tobii Pro Glasses",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/6671b209-a4ef-439e-964e-d73357b3e9d9",
    "llm_summary": "**Summary:** The ROS module for Tobii Pro Glasses is a software integration that enables seamless communication between Tobii Pro Glasses and the Robot Operating System (ROS). It facilitates real-time eye-tracking data collection and analysis within ROS-based robotic systems.  \n\n**Applications:** This technology is applicable in human-robot interaction research, assistive robotics, and usability studies in industries such as healthcare, automotive, and consumer electronics.  \n\n**Problem Solved:** The module addresses the challenge of integrating Tobii Pro Glasses' eye-tracking capabilities with ROS, enabling researchers and developers to leverage eye-tracking data in robotics applications more efficiently.",
    "llm_teaser": "\"Unlock seamless integration of Tobii Pro Glasses with ROS, enabling real-time eye-tracking data for advanced robotics and human-machine interaction research.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Ballbot with Spherical Induction Motor",
    "ip_number": "2016-164",
    "published_date": "Jan 16th, 2020",
    "ip_description": "The invention is a further improvement on the patented \"ballbot\" technology, relying on a new spherical induction motor. It enables a mobile robot to essentially eliminate major mechanical parts in favor of direct electromechanical action.The invention is a further improvement on the patented \"ballbot\" technology, relying on a new spherical induction motor.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/d845c302-5c6b-4b50-8b41-727f249fd2b4",
    "llm_summary": "**Summary:** The technology is an enhanced version of the patented \"ballbot,\" utilizing a new spherical induction motor to enable mobile robots to operate with fewer mechanical components through direct electromechanical action. This innovation simplifies the robot's design and improves efficiency.  \n\n**Applications:** Potential use cases include robotics for manufacturing, healthcare assistance, and autonomous mobile platforms in logistics or service industries.  \n\n**Problem Solved:** The technology addresses the complexity and inefficiency of traditional ballbot designs by reducing reliance on mechanical parts and enabling smoother, more direct motion control.",
    "llm_teaser": "\"Revolutionizing mobility, the Ballbot with Spherical Induction Motor eliminates complex mechanical systems, enabling seamless, direct electromechanical movement for unparalleled agility and efficiency.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Tiny Face Detector",
    "ip_number": "2018-039",
    "published_date": "Jan 16th, 2020",
    "ip_description": "Though tremendous strides have been made in object recognition, one of the remaining open challenges is detecting small objects. We explore three aspects of the problem in the context of finding small faces: the role of scale invariance, image resolution, and contextual reasoning.\n\nWhile most recognition approaches aim to be scale-invariant, the cues for recognizing a 3px tall face are fundamentally different than those for recognizing a 300px tall face. We take a different approach and train separate detectors for different scales. To maintain efficiency, detectors are trained in a multi-task fashion: they make use of features extracted from multiple layers of single (deep) feature hierarchy. While training detectors for large objects is straightforward, the crucial challenge remains training detectors for small objects.We show that context is crucial, and define templates that make use of massively-large receptive fields (where 99% of the template extends beyond the object of interest).\n\nFinally, we explore the role of scale in pre-trained deep networks, providing ways to extrapolate networks tuned for limited scales to rather extreme ranges. We demonstrate state-of-the-art results on massively-bench-marked face datasets (FDDB and WIDER FACE). In particular, when compared to prior art on WIDER FACE, our results reduce error by a factor of 2 (our models produce an AP of 82% while prior art ranges from 29-64%).\n\nPlease read our paper that describes this intellectual property in detail at:https://arxiv.org/abs/1612.04402\n\nVisit our project website at:https://www.cs.cmu.edu/~peiyunh/tiny/",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/aa202378-82fb-410f-8f77-130bdf569360",
    "llm_summary": "**Summary:** The Tiny Face Detector is a state-of-the-art technology that addresses the challenge of detecting small objects, specifically small faces, by training separate detectors for different scales using a multi-task approach. It leverages massively-large receptive fields and contextual reasoning to improve accuracy, achieving an 82% average precision (AP) on the WIDER FACE dataset, significantly outperforming prior methods.  \n\n**Applications:** This technology is applicable in surveillance systems, facial recognition in low-resolution images, and enhancing object detection in industries like security, retail, and social media.  \n\n**Problem Solved:** It solves the problem of detecting small objects, particularly small faces, by overcoming the limitations of scale-invariant approaches and improving accuracy in scenarios where objects are extremely small or low-resolution.",
    "llm_teaser": "\"Revolutionizing small object detection, Tiny Face Detector achieves state-of-the-art accuracy by leveraging scale-specific models, massive contextual reasoning, and deep feature hierarchies, reducing error rates by 50% on benchmark datasets like WIDER FACE.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "A motion planner for visual inspection of infrastructure using flying robots",
    "ip_number": "2018-046",
    "published_date": "Jan 16th, 2020",
    "ip_description": "This invention generates a trajectory based on a set of planes, an obstacle map, and a localizability map as input. The trajectory is then executed by the robot to inspect a structure. The trajectory avoids obstacles, can respect a localizability metric, and covers a structure.\nThis technology is mainly software.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/05367bd8-9ebe-46f9-b370-1d3755eb6bab",
    "llm_summary": "**Summary:** This technology is a motion planner for flying robots that generates a trajectory for visual inspection of infrastructure. It uses input data such as a set of planes, an obstacle map, and a localizability map to create a path that avoids obstacles, respects localizability metrics, and ensures full coverage of the structure. The solution is primarily software-based.\n\n**Applications:**  \n1. Infrastructure inspection (e.g., bridges, buildings, pipelines).  \n2. Maintenance and monitoring of industrial facilities.  \n3. Autonomous drone operations in complex environments.  \n\n**Problem Solved:** The technology addresses the challenge of autonomously planning safe and efficient inspection paths for flying robots in environments with obstacles and varying localizability conditions.",
    "llm_teaser": "\"Revolutionize infrastructure inspection with a cutting-edge motion planner that enables flying robots to autonomously navigate complex environments, avoid obstacles, ensure optimal localizability, and achieve complete structural coverage\u2014all through intelligent software-driven trajectory generation.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Method and apparatus for accessible tables",
    "ip_number": "2015-315",
    "published_date": "Jan 16th, 2020",
    "ip_description": "Interacting with the electronic displays such as the World Wide Web and mobile devices is difficult for the visually challenged. Currently screen reading devices are used that read words that appear on the page. However, these devices provide poor accessibility to tables because tables can be electronically described in many different ways. In this invention, we provide a method and apparatus for improving visual access to tables. The method detects that a table occurs in the page and dynamically extracts (or rewrites) the table into an electronic description more suitable for reading via a reading device. In experimental results, we have evidence that tables can be detected and extracted (or rewritten) with high accuracy through the application of machine learning to the electronic representation of the page.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/f4b42aa5-3b30-4340-ad6b-08bbaaec27fc",
    "llm_summary": "**Summary:**  \nThis invention provides a method and apparatus for improving accessibility to tables on electronic displays for visually challenged users. It detects tables on a page and dynamically extracts or rewrites them into an electronic description optimized for screen reading devices, leveraging machine learning for high accuracy in detection and extraction.\n\n**Applications:**  \n1. Web accessibility tools for visually impaired users.  \n2. Mobile device accessibility enhancements.  \n3. Assistive technology for education and workplace environments.  \n\n**Problem Solved:**  \nThe technology addresses the difficulty visually challenged users face in accessing tables on electronic displays, as current screen reading devices struggle with the varied electronic descriptions of tables.",
    "llm_teaser": "\"Revolutionizing accessibility for the visually impaired, this innovative technology uses machine learning to dynamically detect and rewrite tables into screen-reader-friendly formats, ensuring accurate and seamless access to tabular data on digital platforms.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Never Ending Language Learner (NELL)",
    "ip_number": "2015-139",
    "published_date": "Jan 16th, 2020",
    "ip_description": "NELL a research project that attempts to create a computer system that learns over time to read the web. Since January 2010, our computer system called NELL (Never-Ending Language Learner) has been running continuously, attempting to perform two tasks each day:\n\t\u2022\tFirst, it attempts to \"read,\" or extract facts from text found in hundreds of millions of web pages (e.g.,playsInstrument(George_Harrison, guitar)).\n\t\u2022\tSecond, it attempts to improve its reading competence, so that tomorrow it can extract more facts from the web, more accurately.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/e588bfb9-e8cf-40e4-ac88-1af3b8c0ca16",
    "llm_summary": "**Summary:**  \nNELL (Never-Ending Language Learner) is a computer system designed to continuously learn and extract facts from hundreds of millions of web pages. It improves its reading competence over time, enabling it to extract more accurate and comprehensive information daily.\n\n**Applications:**  \n- Natural language processing and machine learning research.  \n- Knowledge base construction for AI systems and search engines.  \n- Data extraction and analysis for industries relying on web-based information.  \n\n**Problem Solved:**  \nNELL addresses the challenge of automating the extraction and continuous improvement of structured knowledge from vast, unstructured web content, reducing the need for manual data curation.",
    "llm_teaser": "\"NELL, the Never-Ending Language Learner, is an AI system that continuously reads and learns from the web, autonomously improving its ability to extract and refine knowledge, unlocking a self-evolving understanding of the world.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "CDEC Improvements",
    "ip_number": "2016-069",
    "published_date": "Jan 16th, 2020",
    "ip_description": "CDEC is a Decoder, aligner, and model optimizer for statistical machine translation and other structured prediction models based on (mostly) context-free formalisms.\nIt is released under an Apache v2.0 license. \n\nAs initially described in C. Dyer et al. In Proceedings of ACL, July 2010.\nhttps://github.com/redpony/cdec",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/15b6257c-79e6-4992-b86f-3e86db390277",
    "llm_summary": "**Summary:** CDEC is a tool for decoding, aligning, and optimizing models in statistical machine translation and structured prediction, primarily using context-free formalisms. It is open-source, released under the Apache v2.0 license, and was initially described in a 2010 ACL publication.  \n\n**Applications:** CDEC is used in statistical machine translation, structured prediction tasks, and natural language processing applications.  \n\n**Problem Solved:** It addresses the challenge of efficiently decoding and optimizing models for machine translation and other structured prediction tasks, improving accuracy and performance.",
    "llm_teaser": "\"Revolutionize your machine translation with CDEC: a powerful, open-source decoder and model optimizer that enhances structured prediction models, delivering unparalleled accuracy and efficiency under the Apache v2.0 license.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Centralized Automated Modeling of Power Systems",
    "ip_number": "2017-152",
    "published_date": "Jan 16th, 2020",
    "ip_description": "\"Centralized Automated Modeling of Power Systems\" was written and tested using MATLAB R20 16b. For any general power system topology specified by the user, this software is capable of performing the following functionalities in an automated manner: symbolically deriving the interconnected state space model for the system, finding the equilibrium of the system if any exists. linearizing the system around a given operating point. determining which states contribute to instabilities through participation factor analysis, calculating the eigenvalues of the system, and automatically generating and running a MATLAB script which simulates and plots the dynamic response of the system.\n\nIn order to enhance an easier integration of new technologies into power systems, a modular object-oriented design approach is used. MATLAB classes are defined for each component. and the dynamics of each component are expressed symbolically in a common framework using the Symbolic Math Toolbox. Currently the software contains 18 different components and additional components will be included in future versions of the software. These components include 9 different synchronous machine models with varying levels of complexity and control, two load models, two transmission line models, an induction machine model, a flywheel model with power electronic control, a solar PV model, a battery model, and an infinite bus model.\n\nAfter the user specifies the components and the topology of the power system, the software will symbolically derive the state space model of the interconnected system in an automated manner. The interconnection of dynamic modules may lead to dependent state variables, which are eliminated automatically through the software, resulting in a state space model which is in the form of ordinary differential equations.\n\nAdditionally. given parameters of each component specified by the user, the software can automatically solve for the equilibrium of the system if any exists. Furthermore, it can automatically linearize the system around a given operating point and can calculate the eigenvalues of the system for stability analysis. Also, by calculating participation factors, the software can determine which states contribute to instabilities. Finally, given initial conditions specified by the user, this software is capable of automatically creating and running a MATLAB script for simulating the dynamic response of the system for a given amount of time.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/afaabc48-3d81-4469-88a0-0f75d71aeb7e",
    "llm_summary": "**Summary:**  \n\"Centralized Automated Modeling of Power Systems\" is a MATLAB-based software that automates the modeling, analysis, and simulation of power systems. It symbolically derives state space models, finds equilibria, linearizes systems, performs stability analysis, and generates simulation scripts for dynamic response. The software uses a modular, object-oriented design with 18 predefined components, including synchronous machines, loads, and renewable energy models.\n\n**Applications:**  \n1. Power system stability and dynamic response analysis.  \n2. Integration of renewable energy technologies into power grids.  \n3. Research and development of advanced power system control strategies.  \n\n**Problem Solved:**  \nThis technology addresses the complexity of modeling and analyzing interconnected power systems, enabling automated derivation of state space models, stability analysis, and dynamic simulation, which simplifies the integration of new technologies and improves system reliability.",
    "llm_teaser": "\"Revolutionize power system analysis with automated, modular modeling\u2014seamlessly derive state space models, analyze stability, and simulate dynamic responses in MATLAB, all while integrating new technologies with ease.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Natural Language Instructions for Collaborative Manipulation Corpus",
    "ip_number": "2017-076",
    "published_date": "Jan 16th, 2020",
    "ip_description": "This is a dataset which is comprised of natural language instructions used to instruct a robot in picking up objects in a cluttered environment. It was crowd-sourced via Amazon Mechanical Turk user studies and contains metadeta pertaining to the corpus such as hand-coded labeling of characteristic features as well as user-specific data collected during the studies like demographics and feedback. Note that no personally identifying data is included (such as names or addresses of study participants).",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/3304188d-3c2e-44c9-ade9-91dfd3b168c0",
    "llm_summary": "**Summary:** This dataset contains natural language instructions for guiding robots in picking up objects in cluttered environments. It was crowd-sourced via Amazon Mechanical Turk and includes metadata such as hand-coded feature labels, user demographics, and feedback, without personally identifying information.  \n\n**Applications:** Robotics, human-robot collaboration, and natural language processing for task automation.  \n\n**Problem Solved:** The dataset addresses the challenge of enabling robots to understand and execute complex, natural language instructions in real-world, cluttered environments.",
    "llm_teaser": "\"Revolutionize robot collaboration with a crowd-sourced dataset of natural language instructions, enabling precise object manipulation in cluttered environments while capturing rich metadata for enhanced learning and adaptability.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Constrained Question Recommendation Algorithm",
    "ip_number": "2014-222",
    "published_date": "Jan 16th, 2020",
    "ip_description": "In contrast to traditional product recommendation, question recommendation in discussion forums should simultaneously consider constraints on both students and questions. These considerations include (1) Load Balancing - students should not be over-burdened with too many requests; and (2) Expertise Matching - matching students' abilities to the difficulty of unanswered questions, which in turn positions students to contribute meaningfully to the forum. In this work, we have proposed, implemented, and evaluated a novel constrained question recommendation approach to address the above considerations. In particular, from a technical perspective, we designed a context-aware matrix factorization model to predict students' preferences over questions and then built a max cost flow model to manage the constraints.\nThis package can be integrated with online discussion forums to ask as 'just in time' support for productive community interactions within those forums.\nhttps://libraries.io/github/DANCEcollaborative/social_recommendation",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/7668c01f-162a-4974-95ab-d0983d4c798c",
    "llm_summary": "**Summary:** The Constrained Question Recommendation Algorithm is a novel approach designed to recommend questions in discussion forums by balancing student workload and matching expertise. It uses a context-aware matrix factorization model to predict student preferences and a max cost flow model to manage constraints like load balancing and expertise matching.  \n\n**Applications:** This technology can be integrated into online discussion forums, educational platforms, and community-driven Q&A systems to enhance engagement and productivity.  \n\n**Problem Solved:** It addresses the challenge of effectively recommending questions to students in forums by ensuring they are not overburdened and are matched with questions that align with their expertise, fostering meaningful contributions.",
    "llm_teaser": "\"Revolutionize online learning forums with our Constrained Question Recommendation Algorithm, which intelligently balances student workload and expertise to foster meaningful, productive discussions\u2014ensuring no question goes unanswered and no student is overwhelmed.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Agent Supported Synchronous Collaboration in MOOCs",
    "ip_number": "2015-043",
    "published_date": "Jan 16th, 2020",
    "ip_description": "A major limitation of the current generation of Massive Open Online Courses (MOOCs) is a lack of opportunity for students to make use of each other as resources. A synchronous collaboration intervention has been developed to address these limitations.\nThe intervention makes synchronous collaboration opportunities available to students in a MOOC context. Research in Computer-Supported Collaborative Learning has demonstrated that conversational computer agents can serve as effective automated facilitators of synchronous collaborative learning. However, typical MOOC providers do not offer students opportunities for synchronous collaboration, and therefore have not so far benefited from this technology.\nhttps://github.com/DANCEcollaborative/collab-xblock",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/7d65f35e-8705-4ffd-97dd-4b044eb3773d",
    "llm_summary": "**Summary:**  \nThis technology introduces a synchronous collaboration intervention for MOOCs, enabling students to collaborate in real-time. It leverages conversational computer agents to facilitate collaborative learning, addressing the lack of peer interaction in current MOOC platforms.\n\n**Applications:**  \n1. Enhancing student engagement and learning outcomes in MOOCs.  \n2. Supporting collaborative learning in online education platforms.  \n3. Facilitating real-time peer interaction in large-scale online courses.  \n\n**Problem Solved:**  \nThe technology addresses the lack of synchronous collaboration opportunities in MOOCs, which limits students' ability to learn from and interact with peers effectively.",
    "llm_teaser": "\"Revolutionize your MOOC experience with AI-powered synchronous collaboration, enabling real-time peer learning and automated facilitation to unlock the full potential of online education.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "ELASTO-OPTIC MODULATOR INTEGRATED IN HIGH FREQUENCY PIEZOELECTRIC MEMS RESONATOR",
    "ip_number": "2016-088",
    "published_date": "Jan 16th, 2020",
    "ip_description": "The present invention is of an optical modulator that utilizes strain-based refractive index changes through the use of a piezoelectric MEMS resonator. The modulator is comprised of a photonic racetrack resonator made of a piezoelectric/photoelastic material, which is incorporated into the body of the MEMS resonator for mechanical strain to be transferred. The advantages of this type of modulator is that it may be integrated with RF MEMS devices and components on chip and also be scaled to high operational frequencies.\nUnlike present technologies among strain-based modulators, which primarily operate by launching a surface acoustic wave to interact with the optical cavity, this device makes use of laterally vibrating piezoelectric resonators. This design may be used to promote denser integration on chip, and be utilized in a variety of technologies for RF-Photonic applications that incorporate MEMS resonators and photonic integrated circuits. Also, in contrast with other types of optical modulators that involve physical displacements, the present design has an advantage in that its function does not significantly degrade if the device dimensions are modified to operate at a higher frequency due to the strain-based operation. \nThis offers a more reliable interlace for electrically-controlled optical modulation in acousto-optic devices. The invention has been tested experimentally. The demonstration has been made with a monolithic AIN device of 400 nm thickness, but the design may be configured to operate at different frequencies in a variety of piezoelectric materials.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/0d9b4ae0-34ae-49e9-b83d-7e60b41ff030",
    "llm_summary": "**Summary:**  \nThe invention is an optical modulator that uses strain-based refractive index changes via a piezoelectric MEMS resonator. It features a photonic racetrack resonator made of piezoelectric/photoelastic material, enabling high-frequency operation and on-chip integration with RF MEMS devices. The design avoids physical displacement issues, ensuring reliable performance even at scaled dimensions.\n\n**Applications:**  \n1. RF-Photonic applications integrating MEMS resonators and photonic circuits.  \n2. High-frequency optical modulation for telecommunications and signal processing.  \n3. On-chip integration with RF MEMS devices for compact, high-performance systems.  \n\n**Problem Solved:**  \nThe technology addresses the limitations of traditional strain-based modulators, such as reliance on surface acoustic waves and performance degradation at higher frequencies, by using laterally vibrating piezoelectric resonators for stable, scalable optical modulation.",
    "llm_teaser": "\"Revolutionize RF-photonic integration with a strain-based optical modulator that leverages high-frequency piezoelectric MEMS resonators, enabling scalable, reliable, and compact on-chip solutions for advanced acousto-optic applications.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "OntoPronto",
    "ip_number": "2017-066",
    "published_date": "Jan 16th, 2020",
    "ip_description": "User interface tool for developing insider threat indicators using the insider threat indicator ontology.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/53fe2bcf-e0f5-43ab-afcb-69b28169486f",
    "llm_summary": "**Summary:** OntoPronto is a user interface tool designed to facilitate the development of insider threat indicators by leveraging the insider threat indicator ontology. It provides a structured and intuitive platform for creating and managing indicators to detect potential insider threats.  \n\n**Applications:** This tool is applicable in cybersecurity, corporate security, and government sectors where monitoring and mitigating insider threats are critical. It can also be used in organizations with sensitive data or intellectual property requiring robust internal security measures.  \n\n**Problem Solved:** OntoPronto addresses the challenge of systematically identifying and developing insider threat indicators by providing a standardized ontology-based approach, enhancing the accuracy and efficiency of insider threat detection.",
    "llm_teaser": "\"OntoPronto revolutionizes insider threat detection with an intuitive user interface that leverages the insider threat indicator ontology, enabling faster, more accurate identification of potential risks.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "DiscourseDB: A generalizable data infrastructure for discourse data",
    "ip_number": "2017-035",
    "published_date": "Jan 16th, 2020",
    "ip_description": "The significance of the data infrastructure proposed here, referred to as DiscourseDB, lies in its ability to map diverse forms of discussion into a common representation, making it easy to apply analytic tools to different types of social interactions across multiple platforms. Hence, computational models can be applied with little change to any data once imported into DiscourseDB. The structure of DiscourseDB is represented in a relational database as an entity-relation model of connected discourse contributions organized in generic, nested discourse containers.\nhttps://discoursedb.github.io/",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/470d88b2-c8dd-4982-b91c-54ecb208af4c",
    "llm_summary": "**Summary:** DiscourseDB is a data infrastructure that maps diverse forms of discussion into a common representation, enabling the application of computational models to various types of social interactions across multiple platforms. It uses a relational database structured as an entity-relation model to organize discourse contributions in generic, nested containers.\n\n**Applications:**  \n1. Analyzing social interactions across digital platforms.  \n2. Enabling cross-platform discourse research and computational modeling.  \n3. Supporting data-driven insights in fields like social science, education, and communication studies.\n\n**Problem Solved:** DiscourseDB addresses the challenge of analyzing diverse and fragmented discourse data by providing a unified framework that simplifies the application of computational tools across different types of social interactions.",
    "llm_teaser": "\"DiscourseDB revolutionizes discourse analysis by unifying diverse social interactions into a single, adaptable framework, enabling seamless application of computational tools across platforms with minimal customization.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Help Seeking Support through Social Recommendation",
    "ip_number": "2015-044",
    "published_date": "Jan 16th, 2020",
    "ip_description": "A major limitation of the current generation of Massive Open Online Courses (MOOCs) is a lack of opportunity for students to make use of each other as resources. Analyses of attrition and learning in MOOCs both point to the importance of social engagement for motivational support and overcoming difficulties with material and course procedures. A help seeking intervention has been developed to address these limitations.\nThe intervention is designed to support help seeking as well as increasing the probability that help requests will be met with a satisfactory response. While virtually all MOOCs offer threaded discussion affordances where students can post help requests, some students are reticent to ask for help, and even when students do post help requests, many of these requests go unanswered.\nhttps://github.com/DANCEcollaborative/forum-xblock\nA major limitation of the current generation of Massive Open Online Courses (MOOCs) is a lack of opportunity for students to make use of each other as resources. Analyses of attrition and learning in",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/9cf4beb7-59ca-4fd8-8166-b06dce6fb47b",
    "llm_summary": "**Summary:**  \nThis technology introduces a help-seeking intervention for MOOCs to enhance social engagement among students. It supports students in seeking help and increases the likelihood of receiving satisfactory responses to their requests, addressing the limitations of current MOOC discussion forums.\n\n**Applications:**  \n1. Massive Open Online Courses (MOOCs) for improving student engagement and retention.  \n2. Online education platforms to foster peer-to-peer learning and support.  \n\n**Problem Solved:**  \nThe technology addresses the lack of social engagement and support in MOOCs, where students often hesitate to ask for help or receive no responses to their help requests, leading to higher attrition rates and learning difficulties.",
    "llm_teaser": "\"Revolutionize online learning with a social recommendation system that empowers students to seek and receive timely, effective help from peers, boosting engagement and reducing attrition in MOOCs.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "ZFace (3D Facial Landmark Tracking SDK)",
    "ip_number": "2016-076",
    "published_date": "Jan 16th, 2020",
    "ip_description": "Face alignment is the problem of automatically locating detailed facial landmarks across different subjects, illuminations, and viewpoints. Previous methods can be divided into two broad categories. 2D-based methods locate a relatively small number of 2D fiducial points in real time while 3D-based methods fit a high-resolution 3D model offline at a much higher computational cost.\n\nOur approach exploits dense 3D cascade regression, where the facial landmarks are consistent across all poses. In our system the face is annotated completely in 3D by selecting a dense set of 3D points (shape). Binary feature descriptors (appearance) associated with a sparse subset of the landmarks are used to regress projections of 3D points. The method first estimates the location of a dense set of markers and their visibility, then reconstructs face shapes by fitting a part-based 3D model. The method was made possible in part by training on the BU-4D Facial Expression and BP-4D-Spontaneous datasets that contain over 300,000 high-resolution 3D face scans. Because the algorithm makes no assumptions about illumination or surface properties, it can be applied to a wide range of imaging conditions. The method was validated in a series of tests. We found that 3D registration from 2D video effectively handles previously unseen faces with a variety of poses and illuminations. Our implementation runs at 50 fps using a single core of an i7 processor, enabling real-time performance.\nThe software provides facial expression transfer, that enables real-time and person independent avatar animation.\n\nVideo: https://www.youtube.com/watch?v=Xb61CmsPq_I\nPaper: http://www.laszlojeni.com/pub/articles/Jeni15FG_ZFace.pdf\nFace alignment is the problem of automatically locating detailed facial landmarks across different subjects, illuminations, and viewpoints. Previous methods can be divided into two broad categories. 2",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/b978e43d-b04c-4275-bf06-bcdc12949e4f",
    "llm_summary": "**Summary:** ZFace is a 3D facial landmark tracking SDK that uses dense 3D cascade regression to accurately locate facial landmarks across various poses, illuminations, and viewpoints. It achieves real-time performance at 50 fps on a single i7 processor core and enables facial expression transfer for avatar animation. The method leverages training on large datasets (BU-4D and BP-4D-Spontaneous) and handles diverse imaging conditions without assumptions about illumination or surface properties.\n\n**Applications:** Real-time avatar animation for gaming and virtual reality, facial expression analysis for human-computer interaction, and facial landmark tracking for augmented reality applications.\n\n**Problem Solved:** ZFace addresses the challenge of accurately and efficiently tracking detailed 3D facial landmarks in real-time across varying poses, illuminations, and viewpoints, overcoming limitations of traditional 2D and offline 3D methods.",
    "llm_teaser": "\"ZFace revolutionizes facial landmark tracking with real-time, dense 3D cascade regression, delivering unparalleled accuracy across poses, illuminations, and expressions at 50 fps\u2014powering lifelike avatar animation and robust face alignment for any imaging condition.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Large-Scale Video Content Retrieval Through Text Query",
    "ip_number": "2016-079",
    "published_date": "Jan 16th, 2020",
    "ip_description": "Content-based semantic search (e.g., for \u201cbirthday party\u201d) leverages concepts that are automatically detected in the video, such as objects, scenes, and actions (e.g., \u201ccake\u201d, \u201cgift\u201d, \u201ckids\u201d).The method leverages four core concepts:low level features extraction,concept detection,concept adjustmentandinverted indexing. In doing so, the method improves video search efficiency, accuracy & effectiveness. The novel concept adjustment model is a key value proposition. The adjustment increases the consistency of the video representation with the ground truth concept representationThe method can scale up multi-media semantic search (audio and visual) while maintaining state of the art video search performance within a fraction of a second.Video is one of the most popular communication tools today. The ability to search complex events in video based on text queries in large scale without using any video metadata such as titles, human provided keywords or video captions is largely unmet; large-scale content-based semantic search in video is a fundamental problem in multimedia analysis and retrieval. Videos shared may have either no text or only a few words with little relevance to the visual content. Current methods include searching user-generated metadata, often text-based (e.g., titles, descriptions, captions). These methods are unscalable, slow, inconsistent and index videos based on raw concept detection. This technology addresses these long-standing challenges to improve video search experiences through understanding the meaning that lies in the video content. Researchers at CMU have built a system to label videos automatically with textual representations, in a very large scale, for effective search and retrieval.Advances the text retrieval method for video retrievalSupports video summarization, visualization, search & recommendationsScalableto big data collections required for real world applicationsUses a single CPU coreFast-It only takes 0.2 seconds on a single CPU core to search a collection of 100 million internet videosFree of user-generated metadataZero example search (0Ex) -does not require thousands of example videos to detect multimedia events. 0Ex resembles a real-world scenario in which users start the search without any exampleIncreased accuracydue to use of concept adjustment & concise optimization frameworks with interpretationsMulti-media search & recommendations, including mobile or desktop library video searchEnterprise workplace content searchingContent-based semantic search among workplace video files/folders, HR video onboarding/training etc.Supporting law enforcementSearching content circulating on social media involving concepts deemed illegal.In-video advertisingEnabling advertisers to better place ads based on video content and concept occurrences.Education TechnologyContent-based semantic search, recommendations & video summarization of educational videosHealthcare/Bioinformatics",
    "patents": "11,023,523",
    "page_url": "https://cmu.flintbox.com/technologies/75055b8c-7219-45a3-ab39-7164bf861105",
    "llm_summary": "**Summary:**  \nThis technology enables large-scale video content retrieval through text queries by leveraging low-level feature extraction, concept detection, concept adjustment, and inverted indexing. It improves search efficiency, accuracy, and scalability, achieving state-of-the-art performance in under 0.2 seconds on a single CPU core for 100 million videos. It operates without relying on user-generated metadata or requiring example videos for search.\n\n**Applications:**  \n1. Enterprise workplace content searching (e.g., HR training videos, file/folder organization).  \n2. Law enforcement (e.g., identifying illegal content on social media).  \n3. Education technology (e.g., semantic search and summarization of educational videos).  \n\n**Problem Solved:**  \nThe technology addresses the challenge of searching large-scale video content based on text queries without relying on metadata, titles, or captions, which are often inconsistent, unscalable, or irrelevant to the visual content.",
    "llm_teaser": "\"Revolutionize video search with lightning-fast, metadata-free retrieval\u2014find any moment in 100 million videos in just 0.2 seconds using text queries, powered by cutting-edge concept adjustment and scalable semantic analysis.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "QUADS",
    "ip_number": "2016-256",
    "published_date": "Jan 16th, 2020",
    "ip_description": "QUADS is a decision support framework that takes advantage of automatic question answering (QA) technologies to automatically understand and process a decision representation, and produce a final decision by gathering and weighting answers to individual questions using a Bayesian learning and inference process. First, it introduces a directed acyclic graph (DAG) representation for decision processes, which allows decision makers to formulate and organize natural language questions or assertions into an analytic hierarchy, which can be evaluated as part of an ad hoc decision process or as a documented, repeatable analytic process. Then, the decision process is mapped to a Bayesian decision representation, to jointly model the entire decision scenario (including the users' preferences, assertions from QA systems, and hierarchical decision factors) in a unified model. The QUADS framework was implemented as an open source software package, with wrappers for Apache UIMA1 and the CSE framework to support: a) integration of any QA system deployed as a UIMA Aggregate Analysis Engine, and b) configuration, optimization and extension of the QA system with various decision synthesis strategies.\nhttps://github.com/ziy/quads",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/e45a45d8-2f13-4d87-bea2-288b5a943c1a",
    "llm_summary": "**Summary:**  \nQUADS is a decision support framework that uses automatic question answering (QA) technologies and Bayesian learning to process decision representations. It employs a directed acyclic graph (DAG) to organize natural language questions into an analytic hierarchy and maps the decision process to a Bayesian model for unified decision-making. The framework is implemented as open-source software with wrappers for Apache UIMA and CSE, enabling integration with QA systems and customizable decision synthesis strategies.\n\n**Applications:**  \n1. Decision-making in complex, hierarchical scenarios requiring structured analysis.  \n2. Integration with QA systems for automated, repeatable decision processes.  \n3. Industries such as analytics, knowledge management, and decision optimization.  \n\n**Problem Solved:**  \nQUADS addresses the challenge of automating and unifying decision-making processes by integrating QA technologies, user preferences, and hierarchical decision factors into a single, scalable Bayesian model.",
    "llm_teaser": "\"QUADS revolutionizes decision-making by automating complex processes through a Bayesian-driven, natural language framework that integrates user preferences and QA systems into a unified, repeatable, and scalable decision support model.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "TopGen Virtualized Application Service Simulator",
    "ip_number": "2017-016",
    "published_date": "Jan 16th, 2020",
    "ip_description": "TopGen is a virtualized application service simulator for offline exercise and training networks. It configures a single computer host to serve multiple co-hosted virtual services, such as HTTP virtual hosts, DNS views, and SMTP/IMAP virtual mail domains. It includes a network topology definition, \"greybox,\" that can be used with external routing emulators to construct a virtual network topology on the TopGen host.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/2f6b5729-96c1-4894-b173-bde23ace4b05",
    "llm_summary": "**Summary:** TopGen is a virtualized application service simulator that enables a single computer host to run multiple co-hosted virtual services, including HTTP virtual hosts, DNS views, and SMTP/IMAP virtual mail domains. It features a network topology definition called \"greybox,\" which integrates with external routing emulators to create a virtual network topology on the host.  \n\n**Applications:** This technology is ideal for offline exercise and training networks, network simulation for testing and development, and cybersecurity training environments.  \n\n**Problem Solved:** TopGen addresses the need for a scalable and efficient way to simulate complex network environments and application services for training, testing, and development purposes without requiring multiple physical devices.",
    "llm_teaser": "\"TopGen Virtualized Application Service Simulator transforms a single computer into a multi-service training powerhouse, enabling offline network exercises with customizable virtual hosts, DNS views, and mail domains\u2014all powered by an innovative 'greybox' network topology for seamless integration with external routing emulators.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "ROS Effort with Dynamics (REWD) Controllers",
    "ip_number": "2017-002",
    "published_date": "Jan 16th, 2020",
    "ip_description": "The REWD Controllers are a software library that conforms to the ROS (Robot Operating System) ros_control framework of pluggable controllers. It provides a set of robot controllers that output effort commands (usually torque) from various input set points.\nThe controllers uniquely use the DART (Dynamic Animation and Robotics Toolkit) library to incorporate rigid body dynamics calculations in the control loop, enabling their use in arbitrary robotic hardware models. This results in more accurate control and control modes such as gravity compensation. The controllers are intended to be real-time safe while still exposing standard ROS APIs for setting targets, reading progress and cancelling operations.\nThe controllers are currently in use on the HERB platform.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/a36c0e90-ef76-4488-9514-1069ee9de122",
    "llm_summary": "**Summary:**  \nThe REWD Controllers are a ROS-compatible software library that provides robot controllers capable of outputting effort commands (e.g., torque) using rigid body dynamics calculations via the DART library. These controllers enable accurate control, including modes like gravity compensation, and are designed to be real-time safe while maintaining standard ROS APIs for ease of use. They are currently implemented on the HERB platform.\n\n**Applications:**  \n1. Robotics research and development.  \n2. Industrial automation and robotic systems.  \n3. Advanced robotic platforms requiring precise dynamic control.  \n\n**Problem Solved:**  \nThe REWD Controllers address the challenge of achieving accurate and dynamic control in robotic systems by incorporating rigid body dynamics into the control loop, enabling more precise and versatile control modes.",
    "llm_teaser": "\"REWD Controllers revolutionize robotic control by integrating DART-based rigid body dynamics into ROS, delivering precise torque commands, gravity compensation, and real-time safety for versatile hardware applications\u2014powering advanced platforms like HERB.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "Multi-Set Planning: Implementation of planning with families of multiple configuration-space subsets",
    "ip_number": "2015-357",
    "published_date": "Jan 16th, 2020",
    "ip_description": "Multi-Set Planning is an approach to configuration space (C-space) \nplanning in which (a) a large component of planning effort consists of \nevaluating indicator functions on configurations (e.g. checking for \ncollision or stability) and (b) multiple planning queries must be \nprocessed with respect to different, but related, such indicators. This \nis often the case e.g. during sampling-based planning for articulated \nrobot manipulators. The multi-set formulation is an active area of \nresearch; the inventor currently has an academic paper in submission on \nthe topic.\nThis software package contains three components.\n1. An implementation of the Multi-Set Probabalistic RoadMap \n(Multi-Set PAM) as a planner for the Open Motion Planning Library \n(OMPL). The planner allows a family of subsets to be defined via OMPL \nSpace Information objects. The planner operates on an abstracted Roadmap\n class which represents a named collection of progressively densified \nsubgraphs, and uses a Cache class to save and load planner evaluations \nto disk between instantiations of the planner.\n2. Bindings for the Multi-Set PAM for the Open Robotics Automation\nVirtual Environment (OpenRAVE). This includes a Subset Manager OpenRAVE\nmodule which automatically detects subsets and relations thereof from a\ncollection of tagged environment states. These subsets can then be \nreferenced by the Multi-Set PAM OpenRAVE planner interface.\n3. A collection of test scripts and programs.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/b8843569-de15-4cd8-b514-8156c7b14172",
    "llm_summary": "**Summary:** Multi-Set Planning is a configuration space (C-space) planning approach that optimizes planning for multiple related queries by evaluating indicator functions (e.g., collision or stability checks). The technology includes an implementation of Multi-Set Probabilistic RoadMap (Multi-Set PAM) for OMPL, OpenRAVE bindings with a Subset Manager, and test scripts. It enables efficient planning for families of subsets and saves evaluations to disk for reuse.  \n\n**Applications:** This technology is applicable to articulated robot manipulators, robotics automation, and motion planning in virtual environments like OpenRAVE.  \n\n**Problem Solved:** It addresses the inefficiency of repeatedly evaluating similar planning queries by enabling shared evaluations across related subsets, reducing computational effort in sampling-based planning.",
    "llm_teaser": "\"Revolutionize robotic motion planning with Multi-Set Planning: a cutting-edge approach that accelerates complex tasks by efficiently evaluating and reusing configuration-space subsets, enabling faster, more adaptive solutions for articulated manipulators and beyond.\"",
    "university": "Carnegie Mellon University"
  },
  {
    "ip_name": "EMFTA",
    "ip_number": "2016-173",
    "published_date": "Jan 16th, 2020",
    "ip_description": "Model-Based implementation of a Fault-Tree Analysis. The tool provides a way to capture a fault-tree specification in the Eclipse platform, visualize and analyze it.",
    "patents": null,
    "page_url": "https://cmu.flintbox.com/technologies/66a94c26-9e8a-47c1-a7ab-c5a6136b9471",
    "llm_summary": "**Summary:** EMFTA is a model-based tool for Fault-Tree Analysis implemented within the Eclipse platform. It enables users to capture fault-tree specifications, visualize them, and perform analysis to assess system reliability and failure modes.  \n\n**Applications:** This technology is applicable in industries such as aerospace, automotive, and industrial engineering, where system reliability and safety analysis are critical. It is also useful for risk assessment in complex systems and safety-critical software development.  \n\n**Problem Solved:** EMFTA addresses the challenge of efficiently modeling, visualizing, and analyzing fault trees to identify potential system failures and improve reliability in complex systems.",
    "llm_teaser": "\"Revolutionize fault-tree analysis with EMFTA: a model-based tool in the Eclipse platform that simplifies specification, visualization, and analysis for enhanced reliability and precision.\"",
    "university": "Carnegie Mellon University"
  }
]